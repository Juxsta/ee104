{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten,Dropout,Conv2D,LSTM, LeakyReLU, MaxPooling2D\n",
    "import keras\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from os import walk\n",
    "from keras.preprocessing import sequence\n",
    "from scipy.io import wavfile\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "pool=ThreadPool(24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/tf/logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "#%tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wavefile\n",
    "def readwav(file:str):\n",
    "    filepath = Path(file).absolute()\n",
    "    samplerate, data = wavfile.read((filepath))\n",
    "    # print(f\"samplerate = {samplerate}\")\n",
    "    return data,samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTiming(data:np.ndarray,samplerate:int):\n",
    "    length = data.shape[0] / samplerate\n",
    "    return np.arange(0,length,1/samplerate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterSignal(data:np.ndarray,t:np.ndarray,plot:bool=True):\n",
    "    ## normalize input\n",
    "    sig = data/np.amax(data)\n",
    "    sos = signal.butter(1, [.2,3], 'bp', fs=1000, output='sos')\n",
    "    filtered_heart = signal.sosfilt(sos, sig)\n",
    "    norm_heart = filtered_heart/np.amax(filtered_heart)\n",
    "    ## Removing noise\n",
    "    norm_heart = signal.signaltools.wiener(filtered_heart,300)\n",
    "    if plot:\n",
    "        _, (ax1, ax2,ax3) = plt.subplots(3, 1, sharex=True)\n",
    "        ax1.plot(t, sig)\n",
    "        ax1.set_title('Original Heart Rate Signal')\n",
    "        ax2.plot(t, norm_heart)\n",
    "        ax2.set_title('After Bandpass filter')\n",
    "        ax3.plot(t, norm_heart)\n",
    "        ax3.set_title('After Noise Filter')\n",
    "        ax3.set_xlabel('Time [seconds]')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return norm_heart\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSignal(file:str,plot:bool=False,loglevel:str=None):\n",
    "    data,samplerate = readwav(file)\n",
    "    t = getTiming(data,samplerate)\n",
    "    return t,filterSignal(data,t,plot),samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingFolder = \"./heartbeats/classifications\"\n",
    "trainingpath = Path(trainingFolder)\n",
    "paths = [Path(dir[0]) for dir in walk(trainingpath)][1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "# test_data = []\n",
    "plot = False\n",
    "def processFiles(indexedWave,classification,trainIndex):\n",
    "    wav,index = indexedWave\n",
    "    t,d,_ = generateSignal(wav,plot)\n",
    "    # if(index < trainIndex):\n",
    "    train_data.append([d,t,classification])\n",
    "    # else:\n",
    "        # test_data.append([d,t,classification])\n",
    "\n",
    "\n",
    "def get_training_data(path:Path):   \n",
    "    classification = path.name\n",
    "    wavList = glob.glob(str(path.joinpath(\"*.wav\")))\n",
    "    trainIndex=int(math.ceil(len(wavList)*.8)) # use 80% of data for training\n",
    "    pool.map(lambda x: processFiles(x,classification,trainIndex),zip(wavList,range(0,len(wavList))) )\n",
    "    # for wav in zip(wavList,range(0,len(wavList))):\n",
    "    #     processFiles(wav,classification,trainIndex)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data \n",
    "#Loading data from this many files is intensive, speeding up w/ multithreading\n",
    "\n",
    "for path in paths:\n",
    "    get_training_data(path)\n",
    "#train_data=np.array(train_data)\n",
    "#test_data=np.array(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig,time,classification = zip(*train_data)\n",
    "getMaxLength = lambda list: max([len(item) for item in list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 2, 396900)\n"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "x = np.stack([sequence.pad_sequences(dat,maxlen=getMaxLength(dat),dtype='float64') for dat in [sig,time]],axis=1)\n",
    "print(np.shape(x))\n",
    "## integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(np.array(classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(x.shape[0],396900,2)\n",
    "y=tf.keras.utils.to_categorical(y,num_classes=5)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Dense(16, input_shape=(x_train.shape[1],1), activation=\"relu\"))\n",
    "# model.add(Dense(8, activation='tanh'))\n",
    "# model.add(Dense(5, activation='sigmoid'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11294/372255229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(5, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=x_train.shape[1:])\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 23:17:31.867792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:31.877154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:31.877485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:31.878369: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-12 23:17:31.882924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:31.883456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:31.884063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:33.801766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:33.802156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:33.802176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-11-12 23:17:33.802481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-11-12 23:17:33.802550: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2021-11-12 23:17:33.802834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21629 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = Sequential()\n",
    "# # model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# # model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(LSTM(100,return_sequences=False))\n",
    "\n",
    "# # model.add(LSTM(400,return_sequences=False,recurrent_activation='selu',kernel_initializer='lecun_normal', input_shape=(x_train.shape[1],1)))\n",
    "\n",
    "# model.add(Dense(5, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 23:17:34.642641: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 501681600 exceeds 10% of free system memory.\n",
      "2021-11-12 23:17:35.779754: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 501681600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 23:17:38.014219: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25401600 exceeds 10% of free system memory.\n",
      "2021-11-12 23:17:38.014285: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25401600 exceeds 10% of free system memory.\n",
      "2021-11-12 23:17:38.014314: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25401600 exceeds 10% of free system memory.\n",
      "2021-11-12 23:17:40.378161: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2021-11-12 23:19:14.881659: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/20 [========================>.....] - ETA: 10:47 - loss: 1.6375 - accuracy: 0.2647"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=8)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (/root/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:301742)",
      "at S.execute (/root/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:300732)",
      "at S.start (/root/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:296408)",
      "at async t.CellExecutionQueue.executeQueuedCells (/root/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (/root/.vscode-server/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
