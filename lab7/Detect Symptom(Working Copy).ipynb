{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from os import walk\n",
    "from keras.preprocessing import sequence\n",
    "from scipy.io import wavfile\n",
    "import glob\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import heartpy as hp\n",
    "import keras\n",
    "from scipy import fftpack\n",
    "\n",
    "pool=ThreadPool(24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/tf/logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "#%tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wavefile\n",
    "def readwav(file:str):\n",
    "    filepath = Path(file).absolute()\n",
    "    samplerate, data = wavfile.read((filepath))\n",
    "    # print(f\"samplerate = {samplerate}\")\n",
    "    return data,samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTiming(data:np.ndarray,samplerate:int):\n",
    "    length = data.shape[0] / samplerate\n",
    "    return np.arange(0,length,1/samplerate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterSignal(data:np.ndarray,t:np.ndarray,plot:bool=True,length=None,filter=True):\n",
    "    ## normalize input\n",
    "    sig = data/np.amax(data)\n",
    "    norm_heart = data/np.amax(data)\n",
    "    sos = signal.butter(1, [.2,195], 'bp', fs=1000, output='sos')\n",
    "    filtered_heart = signal.sosfilt(sos, sig)\n",
    "    ## Removing noise\n",
    "    noise_heart = signal.signaltools.wiener(filtered_heart,300)\n",
    "    noise_heart = filtered_heart\n",
    "    if(not filter):\n",
    "        noise_heart = norm_heart\n",
    "    if plot:\n",
    "        \n",
    "        _, (ax1, ax2,ax3) = plt.subplots(3, 1, sharex=True)\n",
    "        ax1.plot(t, sig)\n",
    "        ax1.set_title('Original Heart Rate Signal')\n",
    "        ax2.plot(t, norm_heart)\n",
    "        ax2.set_title('After Bandpass filter')\n",
    "        ax3.plot(t, noise_heart)\n",
    "        ax3.set_title('After Noise Filter')\n",
    "        ax3.set_xlabel('Time [seconds]')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return (noise_heart,t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "def generateSignal(file:str,plot:bool=False,loglevel:str=None):\n",
    "    data,samplerate = readwav(file)\n",
    "    length = data.shape[0] / samplerate\n",
    "    lengths.append(length)\n",
    "    t = getTiming(data,samplerate)\n",
    "\n",
    "    sig,t = filterSignal(data,t,plot)\n",
    "    fft = fftpack.fft(sig)\n",
    "    return t,sig,samplerate,fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingFolder = \"./heartbeats/classifications\"\n",
    "trainingpath = Path(trainingFolder)\n",
    "paths = [Path(dir[0]) for dir in walk(trainingpath)][1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "# test_data = []\n",
    "plot = False\n",
    "def processFiles(indexedWave,classification,trainIndex):\n",
    "    wav,index = indexedWave\n",
    "\n",
    "    t,d,samplerate,fft = generateSignal(wav,plot)\n",
    "    try:\n",
    "        wd, data = hp.process(d,samplerate)\n",
    "        points = [data[measure] for measure in data.keys()]\n",
    "        # if(index < trainIndex):\n",
    "        train_data.append([classification,d,fft,*points])\n",
    "    except:\n",
    "        return\n",
    "    # else:\n",
    "        # test_data.append([d,t,classification])\n",
    "\n",
    "\n",
    "def get_training_data(path:Path):   \n",
    "    classification = path.name\n",
    "    wavList = glob.glob(str(path.joinpath(\"*.wav\")))\n",
    "    trainIndex=int(math.ceil(len(wavList)*.8)) # use 80% of data for training\n",
    "    pool.map(lambda x: processFiles(x,classification,trainIndex),zip(wavList,range(0,len(wavList))) )\n",
    "    # for wav in zip(wavList,range(0,len(wavList))):\n",
    "    #     processFiles(wav,classification,trainIndex)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/ma/core.py:5244: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/lib/python3.8/dist-packages/heartpy/analysis.py:778: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  measures['sd1/sd2'] = sd1 / sd2\n",
      "/usr/local/lib/python3.8/dist-packages/scipy/interpolate/fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Load Data \n",
    "#Loading data from this many files is intensive, speeding up w/ multithreading\n",
    "\n",
    "for path in paths:\n",
    "    get_training_data(path)\n",
    "#train_data=np.array(train_data)\n",
    "#test_data=np.array(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification     0\n",
      "signal             0\n",
      "fft                0\n",
      "bpm               37\n",
      "ibi               37\n",
      "sdnn              37\n",
      "sdsd               0\n",
      "rmssd             52\n",
      "pnn20             52\n",
      "pnn50             52\n",
      "hr_mad            37\n",
      "sd1               52\n",
      "sd2               52\n",
      "s                 52\n",
      "sdr               69\n",
      "breathingrate     68\n",
      "dtype: int64\n",
      "classification    0\n",
      "signal            0\n",
      "fft               0\n",
      "bpm               0\n",
      "ibi               0\n",
      "sdnn              0\n",
      "sdsd              0\n",
      "rmssd             0\n",
      "pnn20             0\n",
      "pnn50             0\n",
      "hr_mad            0\n",
      "sd1               0\n",
      "sd2               0\n",
      "s                 0\n",
      "sdr               0\n",
      "breathingrate     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras_preprocessing/sequence.py:98: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  trunc = np.asarray(trunc, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(train_data,columns=[\"classification\",\"signal\",\"fft\",\"bpm\",\"ibi\",\"sdnn\",\"sdsd\",\"rmssd\",\"pnn20\",\"pnn50\",\"hr_mad\",\"sd1\",\"sd2\",\"s\",\"sdr\",\"breathingrate\"])\n",
    "print(df.isna().sum())\n",
    "df = df.dropna()\n",
    "# df = df.fillna(df.median())\n",
    "print(df.isna().sum())\n",
    "\n",
    "# print(df[[\"signal\",\"time\"]].values)\n",
    "\n",
    "xs=sequence.pad_sequences(df.signal.values,maxlen=(lambda list: max([len(item) for item in list]))(df.signal.values),dtype=\"float64\")\n",
    "df.signal = xs\n",
    "xf=sequence.pad_sequences(df.fft.values,maxlen=(lambda list: max([len(item) for item in list]))(df.fft.values),dtype=\"float64\")\n",
    "df.fft = xf\n",
    "# xt=sequence.pad_sequences(df.time.values,maxlen=max_length,dtype=\"float64\")\n",
    "\n",
    "# y = df.iloc\n",
    "# sequence.pad_sequences(df[[\"signal\",\"time\"]].values,maxlen=max_length,dtype=\"float64\")\n",
    "# print(df.iloc[2])\n",
    "df = pd.get_dummies(df,columns=[\"classification\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 12)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = lambda df: (df-df.min())/(df.max()-df.min())\n",
    "x = np.array(df.iloc[:,2:14].values,dtype=np.float64)\n",
    "x = np.nan_to_num(np.array(norm(x),dtype=np.float64))\n",
    "y = df.iloc[:,15:]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "# y=tf.keras.utils.to_categorical(np.array(y),num_classes=5)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_2 (Normalizat  (None, 12)               25        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 512)               6656      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171,550\n",
      "Trainable params: 171,525\n",
      "Non-trainable params: 25\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# with strategy.scope():\n",
    "model = Sequential()\n",
    "model.add(layers.Normalization(axis=-1, input_dim=12))\n",
    "model.add(layers.Dense(512, activation=\"selu\"))\n",
    "model.add(layers.Dense(256, activation='selu'))\n",
    "model.add(layers.Dense(128, activation='selu'))\n",
    "\n",
    "model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.9700 - accuracy: 0.5641 - val_loss: 1.2873 - val_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9966 - accuracy: 0.5256 - val_loss: 1.2103 - val_accuracy: 0.4444\n",
      "Epoch 3/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9661 - accuracy: 0.5769 - val_loss: 1.1351 - val_accuracy: 0.5556\n",
      "Epoch 4/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9996 - accuracy: 0.5513 - val_loss: 1.0443 - val_accuracy: 0.6667\n",
      "Epoch 5/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9933 - accuracy: 0.4744 - val_loss: 1.0444 - val_accuracy: 0.6667\n",
      "Epoch 6/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.1055 - accuracy: 0.5000 - val_loss: 1.4159 - val_accuracy: 0.4444\n",
      "Epoch 7/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.2485 - accuracy: 0.4615 - val_loss: 1.1502 - val_accuracy: 0.5556\n",
      "Epoch 8/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0156 - accuracy: 0.5769 - val_loss: 1.4704 - val_accuracy: 0.2222\n",
      "Epoch 9/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0153 - accuracy: 0.4872 - val_loss: 1.1728 - val_accuracy: 0.5556\n",
      "Epoch 10/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 1.0083 - accuracy: 0.6026 - val_loss: 1.4300 - val_accuracy: 0.3333\n",
      "Epoch 11/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9749 - accuracy: 0.5641 - val_loss: 1.0453 - val_accuracy: 0.5556\n",
      "Epoch 12/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9895 - accuracy: 0.5897 - val_loss: 1.1775 - val_accuracy: 0.4444\n",
      "Epoch 13/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9995 - accuracy: 0.5513 - val_loss: 1.5429 - val_accuracy: 0.3333\n",
      "Epoch 14/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0229 - accuracy: 0.5513 - val_loss: 1.1261 - val_accuracy: 0.5556\n",
      "Epoch 15/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9968 - accuracy: 0.5513 - val_loss: 1.0308 - val_accuracy: 0.4444\n",
      "Epoch 16/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0232 - accuracy: 0.5641 - val_loss: 1.1671 - val_accuracy: 0.4444\n",
      "Epoch 17/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0066 - accuracy: 0.4872 - val_loss: 1.2068 - val_accuracy: 0.4444\n",
      "Epoch 18/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9926 - accuracy: 0.5513 - val_loss: 1.0730 - val_accuracy: 0.5556\n",
      "Epoch 19/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 1.0113 - accuracy: 0.4872 - val_loss: 1.0533 - val_accuracy: 0.5556\n",
      "Epoch 20/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9823 - accuracy: 0.5769 - val_loss: 1.0452 - val_accuracy: 0.5556\n",
      "Epoch 21/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9687 - accuracy: 0.6026 - val_loss: 1.2004 - val_accuracy: 0.5556\n",
      "Epoch 22/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0308 - accuracy: 0.5256 - val_loss: 1.1310 - val_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0136 - accuracy: 0.5256 - val_loss: 1.3836 - val_accuracy: 0.3333\n",
      "Epoch 24/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9722 - accuracy: 0.5641 - val_loss: 1.1003 - val_accuracy: 0.7778\n",
      "Epoch 25/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9710 - accuracy: 0.5641 - val_loss: 1.2408 - val_accuracy: 0.4444\n",
      "Epoch 26/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0114 - accuracy: 0.5513 - val_loss: 1.2154 - val_accuracy: 0.4444\n",
      "Epoch 27/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9633 - accuracy: 0.5769 - val_loss: 1.2428 - val_accuracy: 0.4444\n",
      "Epoch 28/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.9596 - accuracy: 0.5128 - val_loss: 1.1102 - val_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9684 - accuracy: 0.5769 - val_loss: 1.1708 - val_accuracy: 0.4444\n",
      "Epoch 30/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9787 - accuracy: 0.5385 - val_loss: 1.0439 - val_accuracy: 0.5556\n",
      "Epoch 31/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9939 - accuracy: 0.5513 - val_loss: 1.1564 - val_accuracy: 0.4444\n",
      "Epoch 32/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9862 - accuracy: 0.5385 - val_loss: 1.2319 - val_accuracy: 0.4444\n",
      "Epoch 33/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0441 - accuracy: 0.5513 - val_loss: 1.2582 - val_accuracy: 0.4444\n",
      "Epoch 34/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9898 - accuracy: 0.5641 - val_loss: 1.3799 - val_accuracy: 0.3333\n",
      "Epoch 35/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0238 - accuracy: 0.5641 - val_loss: 1.1478 - val_accuracy: 0.4444\n",
      "Epoch 36/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9694 - accuracy: 0.5897 - val_loss: 1.3044 - val_accuracy: 0.3333\n",
      "Epoch 37/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.9826 - accuracy: 0.5769 - val_loss: 1.0962 - val_accuracy: 0.5556\n",
      "Epoch 38/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9801 - accuracy: 0.5385 - val_loss: 1.1504 - val_accuracy: 0.3333\n",
      "Epoch 39/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9788 - accuracy: 0.5641 - val_loss: 1.2581 - val_accuracy: 0.3333\n",
      "Epoch 40/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0052 - accuracy: 0.5769 - val_loss: 1.2352 - val_accuracy: 0.4444\n",
      "Epoch 41/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9631 - accuracy: 0.6282 - val_loss: 1.1667 - val_accuracy: 0.5556\n",
      "Epoch 42/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9669 - accuracy: 0.5769 - val_loss: 1.1498 - val_accuracy: 0.5556\n",
      "Epoch 43/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0132 - accuracy: 0.5513 - val_loss: 1.2455 - val_accuracy: 0.3333\n",
      "Epoch 44/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9799 - accuracy: 0.5897 - val_loss: 1.2184 - val_accuracy: 0.4444\n",
      "Epoch 45/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9437 - accuracy: 0.5769 - val_loss: 1.1268 - val_accuracy: 0.4444\n",
      "Epoch 46/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9492 - accuracy: 0.5513 - val_loss: 1.3317 - val_accuracy: 0.3333\n",
      "Epoch 47/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0265 - accuracy: 0.5000 - val_loss: 1.3145 - val_accuracy: 0.3333\n",
      "Epoch 48/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9749 - accuracy: 0.5256 - val_loss: 0.9763 - val_accuracy: 0.5556\n",
      "Epoch 49/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0297 - accuracy: 0.4615 - val_loss: 1.5322 - val_accuracy: 0.4444\n",
      "Epoch 50/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0377 - accuracy: 0.5256 - val_loss: 1.2545 - val_accuracy: 0.3333\n",
      "Epoch 51/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9907 - accuracy: 0.5385 - val_loss: 1.2360 - val_accuracy: 0.4444\n",
      "Epoch 52/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0816 - accuracy: 0.5641 - val_loss: 1.2677 - val_accuracy: 0.3333\n",
      "Epoch 53/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9754 - accuracy: 0.5000 - val_loss: 1.5846 - val_accuracy: 0.4444\n",
      "Epoch 54/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0138 - accuracy: 0.4744 - val_loss: 1.1926 - val_accuracy: 0.4444\n",
      "Epoch 55/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9869 - accuracy: 0.5769 - val_loss: 1.1098 - val_accuracy: 0.6667\n",
      "Epoch 56/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.9586 - accuracy: 0.5897 - val_loss: 1.3486 - val_accuracy: 0.4444\n",
      "Epoch 57/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9586 - accuracy: 0.5769 - val_loss: 1.1008 - val_accuracy: 0.5556\n",
      "Epoch 58/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9872 - accuracy: 0.6026 - val_loss: 1.2933 - val_accuracy: 0.3333\n",
      "Epoch 59/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9537 - accuracy: 0.5641 - val_loss: 1.3063 - val_accuracy: 0.4444\n",
      "Epoch 60/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9804 - accuracy: 0.5513 - val_loss: 1.3676 - val_accuracy: 0.2222\n",
      "Epoch 61/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0037 - accuracy: 0.5000 - val_loss: 1.3013 - val_accuracy: 0.4444\n",
      "Epoch 62/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9637 - accuracy: 0.6026 - val_loss: 1.0955 - val_accuracy: 0.7778\n",
      "Epoch 63/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0569 - accuracy: 0.5385 - val_loss: 0.9224 - val_accuracy: 0.5556\n",
      "Epoch 64/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0163 - accuracy: 0.5256 - val_loss: 1.3895 - val_accuracy: 0.3333\n",
      "Epoch 65/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 1.0327 - accuracy: 0.5641 - val_loss: 1.2649 - val_accuracy: 0.4444\n",
      "Epoch 66/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0993 - accuracy: 0.5513 - val_loss: 1.1684 - val_accuracy: 0.5556\n",
      "Epoch 67/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0330 - accuracy: 0.5513 - val_loss: 1.1229 - val_accuracy: 0.5556\n",
      "Epoch 68/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9459 - accuracy: 0.5641 - val_loss: 1.1010 - val_accuracy: 0.5556\n",
      "Epoch 69/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9589 - accuracy: 0.5641 - val_loss: 1.2066 - val_accuracy: 0.4444\n",
      "Epoch 70/1000\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.9562 - accuracy: 0.6026 - val_loss: 1.3324 - val_accuracy: 0.3333\n",
      "Epoch 71/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9864 - accuracy: 0.5385 - val_loss: 1.2829 - val_accuracy: 0.4444\n",
      "Epoch 72/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9841 - accuracy: 0.5641 - val_loss: 1.2274 - val_accuracy: 0.4444\n",
      "Epoch 73/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9633 - accuracy: 0.5513 - val_loss: 1.2658 - val_accuracy: 0.3333\n",
      "Epoch 74/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.9771 - accuracy: 0.5385 - val_loss: 1.1646 - val_accuracy: 0.6667\n",
      "Epoch 75/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9603 - accuracy: 0.5769 - val_loss: 1.2424 - val_accuracy: 0.5556\n",
      "Epoch 76/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9448 - accuracy: 0.6410 - val_loss: 1.3538 - val_accuracy: 0.2222\n",
      "Epoch 77/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9776 - accuracy: 0.5897 - val_loss: 1.3414 - val_accuracy: 0.3333\n",
      "Epoch 78/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9712 - accuracy: 0.5513 - val_loss: 1.2734 - val_accuracy: 0.2222\n",
      "Epoch 79/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9638 - accuracy: 0.5256 - val_loss: 1.3033 - val_accuracy: 0.3333\n",
      "Epoch 80/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0050 - accuracy: 0.4872 - val_loss: 1.4452 - val_accuracy: 0.2222\n",
      "Epoch 81/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0303 - accuracy: 0.4872 - val_loss: 1.0905 - val_accuracy: 0.4444\n",
      "Epoch 82/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9502 - accuracy: 0.5513 - val_loss: 0.9464 - val_accuracy: 0.6667\n",
      "Epoch 83/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.9634 - accuracy: 0.5513 - val_loss: 1.4242 - val_accuracy: 0.3333\n",
      "Epoch 84/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9357 - accuracy: 0.5641 - val_loss: 1.0709 - val_accuracy: 0.6667\n",
      "Epoch 85/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9991 - accuracy: 0.5513 - val_loss: 0.9274 - val_accuracy: 0.6667\n",
      "Epoch 86/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9899 - accuracy: 0.5769 - val_loss: 1.0785 - val_accuracy: 0.5556\n",
      "Epoch 87/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9736 - accuracy: 0.5769 - val_loss: 1.4329 - val_accuracy: 0.3333\n",
      "Epoch 88/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9508 - accuracy: 0.5385 - val_loss: 1.0772 - val_accuracy: 0.6667\n",
      "Epoch 89/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9693 - accuracy: 0.4744 - val_loss: 1.1162 - val_accuracy: 0.4444\n",
      "Epoch 90/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9896 - accuracy: 0.5641 - val_loss: 1.4710 - val_accuracy: 0.3333\n",
      "Epoch 91/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.9609 - accuracy: 0.5769 - val_loss: 1.2274 - val_accuracy: 0.2222\n",
      "Epoch 92/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9951 - accuracy: 0.5641 - val_loss: 1.4658 - val_accuracy: 0.3333\n",
      "Epoch 93/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9655 - accuracy: 0.5641 - val_loss: 1.4730 - val_accuracy: 0.4444\n",
      "Epoch 94/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9291 - accuracy: 0.6154 - val_loss: 1.2383 - val_accuracy: 0.5556\n",
      "Epoch 95/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9473 - accuracy: 0.5897 - val_loss: 1.0234 - val_accuracy: 0.5556\n",
      "Epoch 96/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9893 - accuracy: 0.5769 - val_loss: 1.4245 - val_accuracy: 0.2222\n",
      "Epoch 97/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9268 - accuracy: 0.5641 - val_loss: 1.2539 - val_accuracy: 0.4444\n",
      "Epoch 98/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9811 - accuracy: 0.5385 - val_loss: 1.2348 - val_accuracy: 0.4444\n",
      "Epoch 99/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9709 - accuracy: 0.5513 - val_loss: 1.3849 - val_accuracy: 0.4444\n",
      "Epoch 100/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0233 - accuracy: 0.5641 - val_loss: 1.3016 - val_accuracy: 0.4444\n",
      "Epoch 101/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.9601 - accuracy: 0.5641 - val_loss: 0.9814 - val_accuracy: 0.5556\n",
      "Epoch 102/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9672 - accuracy: 0.5000 - val_loss: 1.4193 - val_accuracy: 0.2222\n",
      "Epoch 103/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0674 - accuracy: 0.5128 - val_loss: 1.2627 - val_accuracy: 0.4444\n",
      "Epoch 104/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0398 - accuracy: 0.5641 - val_loss: 1.2907 - val_accuracy: 0.4444\n",
      "Epoch 105/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0476 - accuracy: 0.5641 - val_loss: 1.3187 - val_accuracy: 0.1111\n",
      "Epoch 106/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0632 - accuracy: 0.5385 - val_loss: 1.8637 - val_accuracy: 0.3333\n",
      "Epoch 107/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0568 - accuracy: 0.4872 - val_loss: 1.0557 - val_accuracy: 0.6667\n",
      "Epoch 108/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9974 - accuracy: 0.5385 - val_loss: 1.2479 - val_accuracy: 0.5556\n",
      "Epoch 109/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9529 - accuracy: 0.5128 - val_loss: 1.4075 - val_accuracy: 0.3333\n",
      "Epoch 110/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9662 - accuracy: 0.5641 - val_loss: 1.1899 - val_accuracy: 0.4444\n",
      "Epoch 111/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9645 - accuracy: 0.6026 - val_loss: 1.4075 - val_accuracy: 0.3333\n",
      "Epoch 112/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9413 - accuracy: 0.6154 - val_loss: 1.2479 - val_accuracy: 0.3333\n",
      "Epoch 113/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9482 - accuracy: 0.5897 - val_loss: 1.2205 - val_accuracy: 0.4444\n",
      "Epoch 114/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9527 - accuracy: 0.5769 - val_loss: 1.3497 - val_accuracy: 0.3333\n",
      "Epoch 115/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9367 - accuracy: 0.5897 - val_loss: 1.4064 - val_accuracy: 0.2222\n",
      "Epoch 116/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9418 - accuracy: 0.5897 - val_loss: 1.4795 - val_accuracy: 0.3333\n",
      "Epoch 117/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9469 - accuracy: 0.5385 - val_loss: 1.1483 - val_accuracy: 0.6667\n",
      "Epoch 118/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9309 - accuracy: 0.5769 - val_loss: 1.4487 - val_accuracy: 0.2222\n",
      "Epoch 119/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9479 - accuracy: 0.5641 - val_loss: 1.3412 - val_accuracy: 0.3333\n",
      "Epoch 120/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.9272 - accuracy: 0.5513 - val_loss: 1.1602 - val_accuracy: 0.6667\n",
      "Epoch 121/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9531 - accuracy: 0.5897 - val_loss: 1.2826 - val_accuracy: 0.5556\n",
      "Epoch 122/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9258 - accuracy: 0.6282 - val_loss: 1.1332 - val_accuracy: 0.5556\n",
      "Epoch 123/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9273 - accuracy: 0.5385 - val_loss: 1.3432 - val_accuracy: 0.5556\n",
      "Epoch 124/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9186 - accuracy: 0.6154 - val_loss: 1.1711 - val_accuracy: 0.5556\n",
      "Epoch 125/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9495 - accuracy: 0.6026 - val_loss: 1.1317 - val_accuracy: 0.5556\n",
      "Epoch 126/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9708 - accuracy: 0.5513 - val_loss: 1.3587 - val_accuracy: 0.3333\n",
      "Epoch 127/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0036 - accuracy: 0.5000 - val_loss: 1.2033 - val_accuracy: 0.5556\n",
      "Epoch 128/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9518 - accuracy: 0.6026 - val_loss: 1.3687 - val_accuracy: 0.3333\n",
      "Epoch 129/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.9348 - accuracy: 0.6154 - val_loss: 1.2222 - val_accuracy: 0.5556\n",
      "Epoch 130/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9563 - accuracy: 0.5897 - val_loss: 1.1754 - val_accuracy: 0.5556\n",
      "Epoch 131/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9847 - accuracy: 0.5385 - val_loss: 1.2780 - val_accuracy: 0.5556\n",
      "Epoch 132/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9721 - accuracy: 0.5385 - val_loss: 1.2739 - val_accuracy: 0.4444\n",
      "Epoch 133/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9694 - accuracy: 0.5513 - val_loss: 1.4231 - val_accuracy: 0.3333\n",
      "Epoch 134/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9363 - accuracy: 0.5897 - val_loss: 1.3642 - val_accuracy: 0.4444\n",
      "Epoch 135/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9157 - accuracy: 0.6154 - val_loss: 1.0511 - val_accuracy: 0.7778\n",
      "Epoch 136/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9306 - accuracy: 0.5897 - val_loss: 1.3797 - val_accuracy: 0.3333\n",
      "Epoch 137/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9152 - accuracy: 0.5769 - val_loss: 1.0358 - val_accuracy: 0.6667\n",
      "Epoch 138/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.9878 - accuracy: 0.5641 - val_loss: 1.2737 - val_accuracy: 0.3333\n",
      "Epoch 139/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9587 - accuracy: 0.5256 - val_loss: 1.1114 - val_accuracy: 0.7778\n",
      "Epoch 140/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9275 - accuracy: 0.5897 - val_loss: 1.3376 - val_accuracy: 0.3333\n",
      "Epoch 141/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9526 - accuracy: 0.5769 - val_loss: 1.1146 - val_accuracy: 0.6667\n",
      "Epoch 142/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9159 - accuracy: 0.5897 - val_loss: 1.3406 - val_accuracy: 0.3333\n",
      "Epoch 143/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9838 - accuracy: 0.5385 - val_loss: 1.3918 - val_accuracy: 0.3333\n",
      "Epoch 144/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0580 - accuracy: 0.5641 - val_loss: 1.2296 - val_accuracy: 0.3333\n",
      "Epoch 145/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9510 - accuracy: 0.5385 - val_loss: 1.3618 - val_accuracy: 0.4444\n",
      "Epoch 146/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0032 - accuracy: 0.5513 - val_loss: 1.2110 - val_accuracy: 0.5556\n",
      "Epoch 147/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.9667 - accuracy: 0.5769 - val_loss: 1.2619 - val_accuracy: 0.5556\n",
      "Epoch 148/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9299 - accuracy: 0.5769 - val_loss: 1.4937 - val_accuracy: 0.4444\n",
      "Epoch 149/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9493 - accuracy: 0.5385 - val_loss: 1.4018 - val_accuracy: 0.3333\n",
      "Epoch 150/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9203 - accuracy: 0.5897 - val_loss: 1.2832 - val_accuracy: 0.4444\n",
      "Epoch 151/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9323 - accuracy: 0.5385 - val_loss: 1.1425 - val_accuracy: 0.7778\n",
      "Epoch 152/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9476 - accuracy: 0.5641 - val_loss: 1.3235 - val_accuracy: 0.4444\n",
      "Epoch 153/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9909 - accuracy: 0.5897 - val_loss: 1.3704 - val_accuracy: 0.4444\n",
      "Epoch 154/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9732 - accuracy: 0.5641 - val_loss: 1.3406 - val_accuracy: 0.2222\n",
      "Epoch 155/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9431 - accuracy: 0.5641 - val_loss: 1.4167 - val_accuracy: 0.4444\n",
      "Epoch 156/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.9295 - accuracy: 0.5897 - val_loss: 1.3822 - val_accuracy: 0.4444\n",
      "Epoch 157/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9492 - accuracy: 0.5769 - val_loss: 1.1532 - val_accuracy: 0.4444\n",
      "Epoch 158/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9871 - accuracy: 0.5641 - val_loss: 1.3320 - val_accuracy: 0.3333\n",
      "Epoch 159/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9531 - accuracy: 0.5769 - val_loss: 1.3089 - val_accuracy: 0.3333\n",
      "Epoch 160/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9469 - accuracy: 0.6026 - val_loss: 1.4364 - val_accuracy: 0.3333\n",
      "Epoch 161/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9413 - accuracy: 0.5769 - val_loss: 1.1259 - val_accuracy: 0.6667\n",
      "Epoch 162/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9351 - accuracy: 0.5385 - val_loss: 1.1702 - val_accuracy: 0.5556\n",
      "Epoch 163/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9971 - accuracy: 0.4872 - val_loss: 1.4860 - val_accuracy: 0.4444\n",
      "Epoch 164/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9302 - accuracy: 0.5897 - val_loss: 1.5141 - val_accuracy: 0.3333\n",
      "Epoch 165/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 1.0106 - accuracy: 0.5128 - val_loss: 1.2015 - val_accuracy: 0.6667\n",
      "Epoch 166/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9312 - accuracy: 0.6282 - val_loss: 1.3310 - val_accuracy: 0.3333\n",
      "Epoch 167/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8899 - accuracy: 0.6154 - val_loss: 1.2319 - val_accuracy: 0.4444\n",
      "Epoch 168/1000\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.9405 - accuracy: 0.5641 - val_loss: 1.4459 - val_accuracy: 0.2222\n",
      "Epoch 169/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9148 - accuracy: 0.6026 - val_loss: 1.4122 - val_accuracy: 0.3333\n",
      "Epoch 170/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9427 - accuracy: 0.5513 - val_loss: 1.2861 - val_accuracy: 0.4444\n",
      "Epoch 171/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9257 - accuracy: 0.5513 - val_loss: 1.3125 - val_accuracy: 0.3333\n",
      "Epoch 172/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9912 - accuracy: 0.5769 - val_loss: 1.2599 - val_accuracy: 0.5556\n",
      "Epoch 173/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9008 - accuracy: 0.6026 - val_loss: 1.2407 - val_accuracy: 0.4444\n",
      "Epoch 174/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.9429 - accuracy: 0.5769 - val_loss: 1.4539 - val_accuracy: 0.3333\n",
      "Epoch 175/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9816 - accuracy: 0.5641 - val_loss: 1.0626 - val_accuracy: 0.6667\n",
      "Epoch 176/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9850 - accuracy: 0.5385 - val_loss: 1.3914 - val_accuracy: 0.3333\n",
      "Epoch 177/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9777 - accuracy: 0.6026 - val_loss: 1.3807 - val_accuracy: 0.4444\n",
      "Epoch 178/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9769 - accuracy: 0.5385 - val_loss: 1.2015 - val_accuracy: 0.5556\n",
      "Epoch 179/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9491 - accuracy: 0.5385 - val_loss: 1.2598 - val_accuracy: 0.4444\n",
      "Epoch 180/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9208 - accuracy: 0.5769 - val_loss: 1.2845 - val_accuracy: 0.4444\n",
      "Epoch 181/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9491 - accuracy: 0.5513 - val_loss: 1.2090 - val_accuracy: 0.5556\n",
      "Epoch 182/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9349 - accuracy: 0.5897 - val_loss: 1.2364 - val_accuracy: 0.5556\n",
      "Epoch 183/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9161 - accuracy: 0.5897 - val_loss: 1.4075 - val_accuracy: 0.3333\n",
      "Epoch 184/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9143 - accuracy: 0.6026 - val_loss: 1.3451 - val_accuracy: 0.4444\n",
      "Epoch 185/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8917 - accuracy: 0.6026 - val_loss: 1.2895 - val_accuracy: 0.5556\n",
      "Epoch 186/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9731 - accuracy: 0.5897 - val_loss: 1.3613 - val_accuracy: 0.4444\n",
      "Epoch 187/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9159 - accuracy: 0.5769 - val_loss: 1.2027 - val_accuracy: 0.6667\n",
      "Epoch 188/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9283 - accuracy: 0.6026 - val_loss: 1.3481 - val_accuracy: 0.5556\n",
      "Epoch 189/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9163 - accuracy: 0.5513 - val_loss: 1.2162 - val_accuracy: 0.5556\n",
      "Epoch 190/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9166 - accuracy: 0.5385 - val_loss: 1.8318 - val_accuracy: 0.2222\n",
      "Epoch 191/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9809 - accuracy: 0.5897 - val_loss: 1.1206 - val_accuracy: 0.4444\n",
      "Epoch 192/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9015 - accuracy: 0.5897 - val_loss: 1.8256 - val_accuracy: 0.3333\n",
      "Epoch 193/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9015 - accuracy: 0.6026 - val_loss: 1.1461 - val_accuracy: 0.6667\n",
      "Epoch 194/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9902 - accuracy: 0.5769 - val_loss: 1.2691 - val_accuracy: 0.3333\n",
      "Epoch 195/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9224 - accuracy: 0.6154 - val_loss: 1.1182 - val_accuracy: 0.5556\n",
      "Epoch 196/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9084 - accuracy: 0.5513 - val_loss: 1.6791 - val_accuracy: 0.2222\n",
      "Epoch 197/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9649 - accuracy: 0.5385 - val_loss: 1.2074 - val_accuracy: 0.6667\n",
      "Epoch 198/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9264 - accuracy: 0.5769 - val_loss: 1.6718 - val_accuracy: 0.3333\n",
      "Epoch 199/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9280 - accuracy: 0.5256 - val_loss: 1.9184 - val_accuracy: 0.2222\n",
      "Epoch 200/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9705 - accuracy: 0.5256 - val_loss: 1.5515 - val_accuracy: 0.2222\n",
      "Epoch 201/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9632 - accuracy: 0.5385 - val_loss: 1.3157 - val_accuracy: 0.5556\n",
      "Epoch 202/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.9324 - accuracy: 0.6026 - val_loss: 1.4533 - val_accuracy: 0.3333\n",
      "Epoch 203/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9039 - accuracy: 0.6154 - val_loss: 1.2179 - val_accuracy: 0.5556\n",
      "Epoch 204/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9224 - accuracy: 0.5128 - val_loss: 1.3836 - val_accuracy: 0.4444\n",
      "Epoch 205/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9010 - accuracy: 0.6154 - val_loss: 1.2245 - val_accuracy: 0.6667\n",
      "Epoch 206/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9392 - accuracy: 0.6154 - val_loss: 1.3813 - val_accuracy: 0.4444\n",
      "Epoch 207/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8924 - accuracy: 0.5897 - val_loss: 1.2993 - val_accuracy: 0.4444\n",
      "Epoch 208/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9618 - accuracy: 0.5128 - val_loss: 1.1079 - val_accuracy: 0.6667\n",
      "Epoch 209/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8969 - accuracy: 0.6026 - val_loss: 1.1929 - val_accuracy: 0.6667\n",
      "Epoch 210/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9424 - accuracy: 0.5897 - val_loss: 1.2016 - val_accuracy: 0.6667\n",
      "Epoch 211/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9599 - accuracy: 0.5385 - val_loss: 1.3531 - val_accuracy: 0.3333\n",
      "Epoch 212/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9388 - accuracy: 0.5897 - val_loss: 1.0450 - val_accuracy: 0.6667\n",
      "Epoch 213/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9923 - accuracy: 0.5128 - val_loss: 1.4392 - val_accuracy: 0.4444\n",
      "Epoch 214/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9021 - accuracy: 0.5897 - val_loss: 1.2310 - val_accuracy: 0.5556\n",
      "Epoch 215/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9288 - accuracy: 0.5897 - val_loss: 1.1578 - val_accuracy: 0.6667\n",
      "Epoch 216/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9023 - accuracy: 0.5769 - val_loss: 1.1102 - val_accuracy: 0.5556\n",
      "Epoch 217/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8907 - accuracy: 0.5641 - val_loss: 1.4006 - val_accuracy: 0.5556\n",
      "Epoch 218/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9067 - accuracy: 0.5769 - val_loss: 1.3411 - val_accuracy: 0.4444\n",
      "Epoch 219/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9087 - accuracy: 0.5769 - val_loss: 1.1859 - val_accuracy: 0.6667\n",
      "Epoch 220/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9049 - accuracy: 0.6282 - val_loss: 1.1935 - val_accuracy: 0.6667\n",
      "Epoch 221/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8749 - accuracy: 0.5769 - val_loss: 0.9727 - val_accuracy: 0.6667\n",
      "Epoch 222/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9302 - accuracy: 0.5769 - val_loss: 1.3795 - val_accuracy: 0.5556\n",
      "Epoch 223/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8890 - accuracy: 0.5641 - val_loss: 1.2873 - val_accuracy: 0.5556\n",
      "Epoch 224/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8703 - accuracy: 0.6154 - val_loss: 1.2154 - val_accuracy: 0.5556\n",
      "Epoch 225/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8925 - accuracy: 0.5513 - val_loss: 1.4620 - val_accuracy: 0.4444\n",
      "Epoch 226/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8916 - accuracy: 0.6026 - val_loss: 1.3683 - val_accuracy: 0.2222\n",
      "Epoch 227/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9603 - accuracy: 0.5769 - val_loss: 1.4228 - val_accuracy: 0.3333\n",
      "Epoch 228/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9214 - accuracy: 0.6026 - val_loss: 1.2988 - val_accuracy: 0.5556\n",
      "Epoch 229/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9094 - accuracy: 0.6154 - val_loss: 1.3583 - val_accuracy: 0.3333\n",
      "Epoch 230/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9258 - accuracy: 0.5897 - val_loss: 1.6443 - val_accuracy: 0.3333\n",
      "Epoch 231/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9430 - accuracy: 0.5641 - val_loss: 1.9655 - val_accuracy: 0.2222\n",
      "Epoch 232/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9092 - accuracy: 0.6410 - val_loss: 1.0733 - val_accuracy: 0.6667\n",
      "Epoch 233/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8881 - accuracy: 0.6026 - val_loss: 1.4593 - val_accuracy: 0.3333\n",
      "Epoch 234/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8686 - accuracy: 0.5769 - val_loss: 1.4500 - val_accuracy: 0.3333\n",
      "Epoch 235/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9357 - accuracy: 0.5897 - val_loss: 1.1369 - val_accuracy: 0.3333\n",
      "Epoch 236/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9311 - accuracy: 0.5641 - val_loss: 1.1331 - val_accuracy: 0.5556\n",
      "Epoch 237/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9260 - accuracy: 0.6154 - val_loss: 1.4090 - val_accuracy: 0.2222\n",
      "Epoch 238/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9172 - accuracy: 0.5641 - val_loss: 1.1385 - val_accuracy: 0.6667\n",
      "Epoch 239/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8847 - accuracy: 0.5641 - val_loss: 1.4090 - val_accuracy: 0.4444\n",
      "Epoch 240/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8565 - accuracy: 0.6026 - val_loss: 1.6609 - val_accuracy: 0.3333\n",
      "Epoch 241/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9077 - accuracy: 0.5385 - val_loss: 1.4008 - val_accuracy: 0.3333\n",
      "Epoch 242/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9137 - accuracy: 0.5897 - val_loss: 1.4476 - val_accuracy: 0.3333\n",
      "Epoch 243/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9879 - accuracy: 0.5769 - val_loss: 1.6474 - val_accuracy: 0.3333\n",
      "Epoch 244/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9375 - accuracy: 0.5256 - val_loss: 1.6583 - val_accuracy: 0.3333\n",
      "Epoch 245/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9969 - accuracy: 0.4744 - val_loss: 1.2850 - val_accuracy: 0.5556\n",
      "Epoch 246/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8920 - accuracy: 0.5769 - val_loss: 2.1041 - val_accuracy: 0.2222\n",
      "Epoch 247/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9326 - accuracy: 0.5769 - val_loss: 1.3717 - val_accuracy: 0.4444\n",
      "Epoch 248/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9934 - accuracy: 0.5256 - val_loss: 2.1403 - val_accuracy: 0.2222\n",
      "Epoch 249/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 1.0167 - accuracy: 0.5513 - val_loss: 1.4107 - val_accuracy: 0.4444\n",
      "Epoch 250/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9405 - accuracy: 0.5897 - val_loss: 1.4641 - val_accuracy: 0.4444\n",
      "Epoch 251/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9384 - accuracy: 0.5641 - val_loss: 1.6130 - val_accuracy: 0.3333\n",
      "Epoch 252/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8572 - accuracy: 0.6282 - val_loss: 1.0075 - val_accuracy: 0.5556\n",
      "Epoch 253/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9260 - accuracy: 0.5385 - val_loss: 1.5688 - val_accuracy: 0.2222\n",
      "Epoch 254/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9330 - accuracy: 0.5641 - val_loss: 1.2581 - val_accuracy: 0.6667\n",
      "Epoch 255/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8793 - accuracy: 0.5513 - val_loss: 1.1660 - val_accuracy: 0.6667\n",
      "Epoch 256/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8967 - accuracy: 0.5513 - val_loss: 1.3840 - val_accuracy: 0.5556\n",
      "Epoch 257/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9082 - accuracy: 0.6154 - val_loss: 1.6002 - val_accuracy: 0.3333\n",
      "Epoch 258/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9519 - accuracy: 0.5897 - val_loss: 1.7538 - val_accuracy: 0.2222\n",
      "Epoch 259/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.9085 - accuracy: 0.6282 - val_loss: 1.2206 - val_accuracy: 0.5556\n",
      "Epoch 260/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8820 - accuracy: 0.5385 - val_loss: 1.6811 - val_accuracy: 0.2222\n",
      "Epoch 261/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9273 - accuracy: 0.5000 - val_loss: 1.5018 - val_accuracy: 0.4444\n",
      "Epoch 262/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8631 - accuracy: 0.5769 - val_loss: 1.1092 - val_accuracy: 0.6667\n",
      "Epoch 263/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9630 - accuracy: 0.5897 - val_loss: 1.5475 - val_accuracy: 0.4444\n",
      "Epoch 264/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9000 - accuracy: 0.5641 - val_loss: 1.1460 - val_accuracy: 0.5556\n",
      "Epoch 265/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8808 - accuracy: 0.6410 - val_loss: 1.2699 - val_accuracy: 0.5556\n",
      "Epoch 266/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8983 - accuracy: 0.5385 - val_loss: 1.1818 - val_accuracy: 0.5556\n",
      "Epoch 267/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8623 - accuracy: 0.6282 - val_loss: 1.6039 - val_accuracy: 0.3333\n",
      "Epoch 268/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8592 - accuracy: 0.6026 - val_loss: 1.4193 - val_accuracy: 0.3333\n",
      "Epoch 269/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8744 - accuracy: 0.5897 - val_loss: 1.2193 - val_accuracy: 0.4444\n",
      "Epoch 270/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8858 - accuracy: 0.5641 - val_loss: 1.1445 - val_accuracy: 0.6667\n",
      "Epoch 271/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9355 - accuracy: 0.5000 - val_loss: 1.1377 - val_accuracy: 0.4444\n",
      "Epoch 272/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9108 - accuracy: 0.6154 - val_loss: 1.0966 - val_accuracy: 0.6667\n",
      "Epoch 273/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9398 - accuracy: 0.5897 - val_loss: 0.9975 - val_accuracy: 0.6667\n",
      "Epoch 274/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9766 - accuracy: 0.5769 - val_loss: 1.2548 - val_accuracy: 0.4444\n",
      "Epoch 275/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0616 - accuracy: 0.5513 - val_loss: 1.0596 - val_accuracy: 0.6667\n",
      "Epoch 276/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9703 - accuracy: 0.5641 - val_loss: 1.3620 - val_accuracy: 0.4444\n",
      "Epoch 277/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9802 - accuracy: 0.5897 - val_loss: 1.4057 - val_accuracy: 0.4444\n",
      "Epoch 278/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9395 - accuracy: 0.5897 - val_loss: 1.4859 - val_accuracy: 0.3333\n",
      "Epoch 279/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9274 - accuracy: 0.6282 - val_loss: 1.2978 - val_accuracy: 0.5556\n",
      "Epoch 280/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8562 - accuracy: 0.5769 - val_loss: 1.2608 - val_accuracy: 0.6667\n",
      "Epoch 281/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8731 - accuracy: 0.6410 - val_loss: 1.4136 - val_accuracy: 0.4444\n",
      "Epoch 282/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9231 - accuracy: 0.5641 - val_loss: 1.4701 - val_accuracy: 0.4444\n",
      "Epoch 283/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8435 - accuracy: 0.5897 - val_loss: 1.1271 - val_accuracy: 0.6667\n",
      "Epoch 284/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8578 - accuracy: 0.6282 - val_loss: 1.3799 - val_accuracy: 0.4444\n",
      "Epoch 285/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8715 - accuracy: 0.6026 - val_loss: 1.2823 - val_accuracy: 0.4444\n",
      "Epoch 286/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8664 - accuracy: 0.5897 - val_loss: 1.6563 - val_accuracy: 0.3333\n",
      "Epoch 287/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9153 - accuracy: 0.5513 - val_loss: 1.4786 - val_accuracy: 0.2222\n",
      "Epoch 288/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8573 - accuracy: 0.6410 - val_loss: 1.1013 - val_accuracy: 0.7778\n",
      "Epoch 289/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8731 - accuracy: 0.5641 - val_loss: 1.3538 - val_accuracy: 0.6667\n",
      "Epoch 290/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9239 - accuracy: 0.6026 - val_loss: 1.6762 - val_accuracy: 0.3333\n",
      "Epoch 291/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9287 - accuracy: 0.5128 - val_loss: 1.3337 - val_accuracy: 0.4444\n",
      "Epoch 292/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8863 - accuracy: 0.5769 - val_loss: 1.4947 - val_accuracy: 0.4444\n",
      "Epoch 293/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8820 - accuracy: 0.5769 - val_loss: 1.3221 - val_accuracy: 0.4444\n",
      "Epoch 294/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9305 - accuracy: 0.5513 - val_loss: 1.3040 - val_accuracy: 0.5556\n",
      "Epoch 295/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9023 - accuracy: 0.5513 - val_loss: 1.3432 - val_accuracy: 0.4444\n",
      "Epoch 296/1000\n",
      "78/78 [==============================] - 2s 23ms/step - loss: 0.8970 - accuracy: 0.5769 - val_loss: 1.3073 - val_accuracy: 0.6667\n",
      "Epoch 297/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8839 - accuracy: 0.6026 - val_loss: 1.3197 - val_accuracy: 0.4444\n",
      "Epoch 298/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8664 - accuracy: 0.5513 - val_loss: 1.3113 - val_accuracy: 0.4444\n",
      "Epoch 299/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.8581 - accuracy: 0.6154 - val_loss: 1.3561 - val_accuracy: 0.3333\n",
      "Epoch 300/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8494 - accuracy: 0.5513 - val_loss: 1.2163 - val_accuracy: 0.6667\n",
      "Epoch 301/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8476 - accuracy: 0.5897 - val_loss: 1.1879 - val_accuracy: 0.4444\n",
      "Epoch 302/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8753 - accuracy: 0.5641 - val_loss: 1.2840 - val_accuracy: 0.3333\n",
      "Epoch 303/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8466 - accuracy: 0.6667 - val_loss: 1.4492 - val_accuracy: 0.4444\n",
      "Epoch 304/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8614 - accuracy: 0.6026 - val_loss: 1.4664 - val_accuracy: 0.4444\n",
      "Epoch 305/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8890 - accuracy: 0.6154 - val_loss: 1.4558 - val_accuracy: 0.4444\n",
      "Epoch 306/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8703 - accuracy: 0.6154 - val_loss: 1.1054 - val_accuracy: 0.5556\n",
      "Epoch 307/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8737 - accuracy: 0.5513 - val_loss: 1.5839 - val_accuracy: 0.2222\n",
      "Epoch 308/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.8929 - accuracy: 0.5641 - val_loss: 1.2944 - val_accuracy: 0.5556\n",
      "Epoch 309/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8800 - accuracy: 0.6538 - val_loss: 1.1579 - val_accuracy: 0.5556\n",
      "Epoch 310/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9025 - accuracy: 0.5897 - val_loss: 1.0757 - val_accuracy: 0.5556\n",
      "Epoch 311/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9018 - accuracy: 0.5513 - val_loss: 1.4155 - val_accuracy: 0.5556\n",
      "Epoch 312/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8944 - accuracy: 0.5641 - val_loss: 1.8213 - val_accuracy: 0.3333\n",
      "Epoch 313/1000\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.8624 - accuracy: 0.6154 - val_loss: 1.2644 - val_accuracy: 0.5556\n",
      "Epoch 314/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8893 - accuracy: 0.5897 - val_loss: 1.1963 - val_accuracy: 0.6667\n",
      "Epoch 315/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.8250 - accuracy: 0.5641 - val_loss: 1.7475 - val_accuracy: 0.3333\n",
      "Epoch 316/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8494 - accuracy: 0.6154 - val_loss: 1.4852 - val_accuracy: 0.2222\n",
      "Epoch 317/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8171 - accuracy: 0.5897 - val_loss: 1.4867 - val_accuracy: 0.2222\n",
      "Epoch 318/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8720 - accuracy: 0.6154 - val_loss: 1.3649 - val_accuracy: 0.5556\n",
      "Epoch 319/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8463 - accuracy: 0.6026 - val_loss: 1.3565 - val_accuracy: 0.4444\n",
      "Epoch 320/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8635 - accuracy: 0.5641 - val_loss: 1.3084 - val_accuracy: 0.3333\n",
      "Epoch 321/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8430 - accuracy: 0.6026 - val_loss: 1.2598 - val_accuracy: 0.6667\n",
      "Epoch 322/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8796 - accuracy: 0.5641 - val_loss: 1.3941 - val_accuracy: 0.3333\n",
      "Epoch 323/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8315 - accuracy: 0.6282 - val_loss: 1.7142 - val_accuracy: 0.3333\n",
      "Epoch 324/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.8216 - accuracy: 0.6154 - val_loss: 1.7690 - val_accuracy: 0.2222\n",
      "Epoch 325/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9205 - accuracy: 0.5769 - val_loss: 1.3771 - val_accuracy: 0.5556\n",
      "Epoch 326/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8775 - accuracy: 0.5769 - val_loss: 1.3920 - val_accuracy: 0.3333\n",
      "Epoch 327/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8275 - accuracy: 0.6410 - val_loss: 1.3270 - val_accuracy: 0.5556\n",
      "Epoch 328/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7999 - accuracy: 0.6282 - val_loss: 1.5302 - val_accuracy: 0.4444\n",
      "Epoch 329/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9761 - accuracy: 0.6026 - val_loss: 1.1834 - val_accuracy: 0.6667\n",
      "Epoch 330/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8445 - accuracy: 0.6026 - val_loss: 1.2993 - val_accuracy: 0.5556\n",
      "Epoch 331/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8631 - accuracy: 0.5769 - val_loss: 0.9878 - val_accuracy: 0.7778\n",
      "Epoch 332/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8762 - accuracy: 0.5769 - val_loss: 1.2995 - val_accuracy: 0.6667\n",
      "Epoch 333/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8263 - accuracy: 0.6154 - val_loss: 1.4452 - val_accuracy: 0.3333\n",
      "Epoch 334/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8911 - accuracy: 0.6026 - val_loss: 1.4724 - val_accuracy: 0.4444\n",
      "Epoch 335/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8952 - accuracy: 0.5385 - val_loss: 1.2870 - val_accuracy: 0.5556\n",
      "Epoch 336/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.8690 - accuracy: 0.5513 - val_loss: 1.1365 - val_accuracy: 0.5556\n",
      "Epoch 337/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9207 - accuracy: 0.5769 - val_loss: 1.6140 - val_accuracy: 0.3333\n",
      "Epoch 338/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0128 - accuracy: 0.5256 - val_loss: 1.9035 - val_accuracy: 0.2222\n",
      "Epoch 339/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8482 - accuracy: 0.6154 - val_loss: 1.3945 - val_accuracy: 0.3333\n",
      "Epoch 340/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8492 - accuracy: 0.5641 - val_loss: 1.1650 - val_accuracy: 0.6667\n",
      "Epoch 341/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8336 - accuracy: 0.6026 - val_loss: 1.1336 - val_accuracy: 0.7778\n",
      "Epoch 342/1000\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 0.8841 - accuracy: 0.5385 - val_loss: 1.2492 - val_accuracy: 0.7778\n",
      "Epoch 343/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8661 - accuracy: 0.5769 - val_loss: 1.5779 - val_accuracy: 0.3333\n",
      "Epoch 344/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8270 - accuracy: 0.6282 - val_loss: 1.1692 - val_accuracy: 0.5556\n",
      "Epoch 345/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8375 - accuracy: 0.5641 - val_loss: 1.3241 - val_accuracy: 0.5556\n",
      "Epoch 346/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8465 - accuracy: 0.6026 - val_loss: 0.9319 - val_accuracy: 0.6667\n",
      "Epoch 347/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8737 - accuracy: 0.5897 - val_loss: 1.2103 - val_accuracy: 0.5556\n",
      "Epoch 348/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7988 - accuracy: 0.6154 - val_loss: 1.3996 - val_accuracy: 0.4444\n",
      "Epoch 349/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8604 - accuracy: 0.5897 - val_loss: 1.2025 - val_accuracy: 0.5556\n",
      "Epoch 350/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.8147 - accuracy: 0.6667 - val_loss: 1.5571 - val_accuracy: 0.2222\n",
      "Epoch 351/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.8332 - accuracy: 0.5897 - val_loss: 1.1308 - val_accuracy: 0.5556\n",
      "Epoch 352/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8779 - accuracy: 0.5897 - val_loss: 1.2646 - val_accuracy: 0.5556\n",
      "Epoch 353/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8195 - accuracy: 0.6026 - val_loss: 1.6901 - val_accuracy: 0.2222\n",
      "Epoch 354/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8476 - accuracy: 0.5897 - val_loss: 1.1575 - val_accuracy: 0.4444\n",
      "Epoch 355/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9569 - accuracy: 0.5897 - val_loss: 1.1268 - val_accuracy: 0.7778\n",
      "Epoch 356/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0158 - accuracy: 0.5385 - val_loss: 1.3450 - val_accuracy: 0.4444\n",
      "Epoch 357/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9132 - accuracy: 0.5641 - val_loss: 1.3027 - val_accuracy: 0.6667\n",
      "Epoch 358/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8527 - accuracy: 0.5385 - val_loss: 1.2650 - val_accuracy: 0.6667\n",
      "Epoch 359/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8428 - accuracy: 0.5897 - val_loss: 1.2996 - val_accuracy: 0.4444\n",
      "Epoch 360/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.9004 - accuracy: 0.5128 - val_loss: 1.4175 - val_accuracy: 0.3333\n",
      "Epoch 361/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8046 - accuracy: 0.6410 - val_loss: 1.2444 - val_accuracy: 0.4444\n",
      "Epoch 362/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8448 - accuracy: 0.4744 - val_loss: 1.8026 - val_accuracy: 0.2222\n",
      "Epoch 363/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9296 - accuracy: 0.6154 - val_loss: 1.1835 - val_accuracy: 0.5556\n",
      "Epoch 364/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8184 - accuracy: 0.6282 - val_loss: 1.3494 - val_accuracy: 0.4444\n",
      "Epoch 365/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8462 - accuracy: 0.6538 - val_loss: 1.1804 - val_accuracy: 0.5556\n",
      "Epoch 366/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8586 - accuracy: 0.5769 - val_loss: 1.3032 - val_accuracy: 0.6667\n",
      "Epoch 367/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8763 - accuracy: 0.6154 - val_loss: 1.3710 - val_accuracy: 0.6667\n",
      "Epoch 368/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8017 - accuracy: 0.6282 - val_loss: 1.2261 - val_accuracy: 0.5556\n",
      "Epoch 369/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7847 - accuracy: 0.6667 - val_loss: 1.4978 - val_accuracy: 0.4444\n",
      "Epoch 370/1000\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.8030 - accuracy: 0.6026 - val_loss: 1.1012 - val_accuracy: 0.5556\n",
      "Epoch 371/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8331 - accuracy: 0.5897 - val_loss: 1.3810 - val_accuracy: 0.4444\n",
      "Epoch 372/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8114 - accuracy: 0.6282 - val_loss: 1.5908 - val_accuracy: 0.2222\n",
      "Epoch 373/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8923 - accuracy: 0.5769 - val_loss: 1.1718 - val_accuracy: 0.5556\n",
      "Epoch 374/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8745 - accuracy: 0.5513 - val_loss: 1.2793 - val_accuracy: 0.5556\n",
      "Epoch 375/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7991 - accuracy: 0.6410 - val_loss: 1.4831 - val_accuracy: 0.2222\n",
      "Epoch 376/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8313 - accuracy: 0.6410 - val_loss: 1.1702 - val_accuracy: 0.5556\n",
      "Epoch 377/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8774 - accuracy: 0.5513 - val_loss: 1.2254 - val_accuracy: 0.6667\n",
      "Epoch 378/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8531 - accuracy: 0.5897 - val_loss: 1.3046 - val_accuracy: 0.5556\n",
      "Epoch 379/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.8439 - accuracy: 0.5897 - val_loss: 1.4645 - val_accuracy: 0.2222\n",
      "Epoch 380/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0620 - accuracy: 0.5513 - val_loss: 1.6592 - val_accuracy: 0.2222\n",
      "Epoch 381/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9244 - accuracy: 0.5769 - val_loss: 1.1956 - val_accuracy: 0.6667\n",
      "Epoch 382/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9352 - accuracy: 0.5513 - val_loss: 1.0879 - val_accuracy: 0.5556\n",
      "Epoch 383/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8768 - accuracy: 0.5513 - val_loss: 1.3542 - val_accuracy: 0.2222\n",
      "Epoch 384/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8313 - accuracy: 0.6282 - val_loss: 1.8627 - val_accuracy: 0.1111\n",
      "Epoch 385/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8218 - accuracy: 0.6026 - val_loss: 1.3671 - val_accuracy: 0.6667\n",
      "Epoch 386/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7743 - accuracy: 0.6410 - val_loss: 1.3511 - val_accuracy: 0.4444\n",
      "Epoch 387/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8329 - accuracy: 0.6410 - val_loss: 1.4986 - val_accuracy: 0.3333\n",
      "Epoch 388/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7720 - accuracy: 0.6538 - val_loss: 1.0930 - val_accuracy: 0.6667\n",
      "Epoch 389/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8118 - accuracy: 0.5897 - val_loss: 1.2082 - val_accuracy: 0.5556\n",
      "Epoch 390/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8054 - accuracy: 0.6538 - val_loss: 1.5966 - val_accuracy: 0.2222\n",
      "Epoch 391/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7918 - accuracy: 0.6795 - val_loss: 1.2830 - val_accuracy: 0.4444\n",
      "Epoch 392/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8515 - accuracy: 0.6026 - val_loss: 1.4624 - val_accuracy: 0.4444\n",
      "Epoch 393/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8302 - accuracy: 0.5897 - val_loss: 1.1741 - val_accuracy: 0.4444\n",
      "Epoch 394/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8126 - accuracy: 0.6795 - val_loss: 1.4332 - val_accuracy: 0.3333\n",
      "Epoch 395/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8211 - accuracy: 0.6282 - val_loss: 1.7740 - val_accuracy: 0.2222\n",
      "Epoch 396/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8947 - accuracy: 0.6154 - val_loss: 1.8004 - val_accuracy: 0.3333\n",
      "Epoch 397/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8414 - accuracy: 0.6282 - val_loss: 1.2441 - val_accuracy: 0.5556\n",
      "Epoch 398/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.7853 - accuracy: 0.6282 - val_loss: 1.5108 - val_accuracy: 0.4444\n",
      "Epoch 399/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7956 - accuracy: 0.6154 - val_loss: 1.1476 - val_accuracy: 0.6667\n",
      "Epoch 400/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8341 - accuracy: 0.5897 - val_loss: 1.1808 - val_accuracy: 0.6667\n",
      "Epoch 401/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8292 - accuracy: 0.6538 - val_loss: 1.3698 - val_accuracy: 0.5556\n",
      "Epoch 402/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8067 - accuracy: 0.6410 - val_loss: 1.3471 - val_accuracy: 0.6667\n",
      "Epoch 403/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7779 - accuracy: 0.6538 - val_loss: 1.2032 - val_accuracy: 0.5556\n",
      "Epoch 404/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8350 - accuracy: 0.6154 - val_loss: 1.4747 - val_accuracy: 0.5556\n",
      "Epoch 405/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8041 - accuracy: 0.6282 - val_loss: 1.3380 - val_accuracy: 0.5556\n",
      "Epoch 406/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8431 - accuracy: 0.5641 - val_loss: 1.1980 - val_accuracy: 0.5556\n",
      "Epoch 407/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.8196 - accuracy: 0.6410 - val_loss: 1.3995 - val_accuracy: 0.3333\n",
      "Epoch 408/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9170 - accuracy: 0.5897 - val_loss: 1.6812 - val_accuracy: 0.4444\n",
      "Epoch 409/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8363 - accuracy: 0.6282 - val_loss: 1.2310 - val_accuracy: 0.6667\n",
      "Epoch 410/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8179 - accuracy: 0.6795 - val_loss: 1.4211 - val_accuracy: 0.3333\n",
      "Epoch 411/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8784 - accuracy: 0.6154 - val_loss: 1.3267 - val_accuracy: 0.4444\n",
      "Epoch 412/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7936 - accuracy: 0.6282 - val_loss: 1.5545 - val_accuracy: 0.3333\n",
      "Epoch 413/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8413 - accuracy: 0.6026 - val_loss: 1.4743 - val_accuracy: 0.3333\n",
      "Epoch 414/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8060 - accuracy: 0.6026 - val_loss: 1.2826 - val_accuracy: 0.5556\n",
      "Epoch 415/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8063 - accuracy: 0.6667 - val_loss: 1.5078 - val_accuracy: 0.6667\n",
      "Epoch 416/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.7885 - accuracy: 0.6410 - val_loss: 1.4312 - val_accuracy: 0.4444\n",
      "Epoch 417/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7547 - accuracy: 0.6795 - val_loss: 0.9233 - val_accuracy: 0.6667\n",
      "Epoch 418/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7820 - accuracy: 0.6667 - val_loss: 1.2402 - val_accuracy: 0.6667\n",
      "Epoch 419/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8488 - accuracy: 0.6154 - val_loss: 1.3364 - val_accuracy: 0.4444\n",
      "Epoch 420/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7960 - accuracy: 0.6795 - val_loss: 1.5240 - val_accuracy: 0.4444\n",
      "Epoch 421/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8402 - accuracy: 0.5897 - val_loss: 1.2700 - val_accuracy: 0.6667\n",
      "Epoch 422/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7603 - accuracy: 0.6795 - val_loss: 1.3584 - val_accuracy: 0.4444\n",
      "Epoch 423/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7875 - accuracy: 0.6667 - val_loss: 1.4667 - val_accuracy: 0.4444\n",
      "Epoch 424/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8073 - accuracy: 0.5769 - val_loss: 1.4208 - val_accuracy: 0.4444\n",
      "Epoch 425/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.8529 - accuracy: 0.5897 - val_loss: 1.9990 - val_accuracy: 0.2222\n",
      "Epoch 426/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9571 - accuracy: 0.5385 - val_loss: 1.4835 - val_accuracy: 0.2222\n",
      "Epoch 427/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8529 - accuracy: 0.5897 - val_loss: 1.1525 - val_accuracy: 0.5556\n",
      "Epoch 428/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8112 - accuracy: 0.6410 - val_loss: 1.2423 - val_accuracy: 0.5556\n",
      "Epoch 429/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7721 - accuracy: 0.6282 - val_loss: 1.4319 - val_accuracy: 0.4444\n",
      "Epoch 430/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7601 - accuracy: 0.6410 - val_loss: 1.3401 - val_accuracy: 0.5556\n",
      "Epoch 431/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7840 - accuracy: 0.6538 - val_loss: 1.3226 - val_accuracy: 0.5556\n",
      "Epoch 432/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8363 - accuracy: 0.6667 - val_loss: 1.3429 - val_accuracy: 0.5556\n",
      "Epoch 433/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7909 - accuracy: 0.6923 - val_loss: 1.0581 - val_accuracy: 0.5556\n",
      "Epoch 434/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7775 - accuracy: 0.6667 - val_loss: 1.6041 - val_accuracy: 0.3333\n",
      "Epoch 435/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8161 - accuracy: 0.6795 - val_loss: 1.4746 - val_accuracy: 0.3333\n",
      "Epoch 436/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7985 - accuracy: 0.6538 - val_loss: 1.2082 - val_accuracy: 0.6667\n",
      "Epoch 437/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7951 - accuracy: 0.6282 - val_loss: 1.5971 - val_accuracy: 0.3333\n",
      "Epoch 438/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7961 - accuracy: 0.6154 - val_loss: 1.7354 - val_accuracy: 0.2222\n",
      "Epoch 439/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8026 - accuracy: 0.6410 - val_loss: 1.2536 - val_accuracy: 0.5556\n",
      "Epoch 440/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7588 - accuracy: 0.6410 - val_loss: 1.3198 - val_accuracy: 0.5556\n",
      "Epoch 441/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8371 - accuracy: 0.6282 - val_loss: 1.6767 - val_accuracy: 0.3333\n",
      "Epoch 442/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8386 - accuracy: 0.6026 - val_loss: 1.9612 - val_accuracy: 0.2222\n",
      "Epoch 443/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.7765 - accuracy: 0.6154 - val_loss: 1.2534 - val_accuracy: 0.5556\n",
      "Epoch 444/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8196 - accuracy: 0.6282 - val_loss: 1.4515 - val_accuracy: 0.4444\n",
      "Epoch 445/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8210 - accuracy: 0.6154 - val_loss: 1.4396 - val_accuracy: 0.4444\n",
      "Epoch 446/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7763 - accuracy: 0.6154 - val_loss: 1.5726 - val_accuracy: 0.3333\n",
      "Epoch 447/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7613 - accuracy: 0.6795 - val_loss: 1.4251 - val_accuracy: 0.4444\n",
      "Epoch 448/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7191 - accuracy: 0.7308 - val_loss: 1.3796 - val_accuracy: 0.4444\n",
      "Epoch 449/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7171 - accuracy: 0.6667 - val_loss: 1.1513 - val_accuracy: 0.6667\n",
      "Epoch 450/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8049 - accuracy: 0.6282 - val_loss: 1.4049 - val_accuracy: 0.5556\n",
      "Epoch 451/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.8319 - accuracy: 0.5897 - val_loss: 1.1129 - val_accuracy: 0.5556\n",
      "Epoch 452/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7220 - accuracy: 0.7179 - val_loss: 1.3548 - val_accuracy: 0.5556\n",
      "Epoch 453/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7508 - accuracy: 0.6923 - val_loss: 1.1158 - val_accuracy: 0.5556\n",
      "Epoch 454/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7624 - accuracy: 0.6795 - val_loss: 1.7686 - val_accuracy: 0.2222\n",
      "Epoch 455/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7669 - accuracy: 0.6667 - val_loss: 1.5460 - val_accuracy: 0.3333\n",
      "Epoch 456/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8073 - accuracy: 0.5897 - val_loss: 1.3254 - val_accuracy: 0.5556\n",
      "Epoch 457/1000\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.8016 - accuracy: 0.6538 - val_loss: 2.1499 - val_accuracy: 0.2222\n",
      "Epoch 458/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9500 - accuracy: 0.6154 - val_loss: 2.3881 - val_accuracy: 0.1111\n",
      "Epoch 459/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9537 - accuracy: 0.5641 - val_loss: 1.5052 - val_accuracy: 0.3333\n",
      "Epoch 460/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7965 - accuracy: 0.6282 - val_loss: 1.9177 - val_accuracy: 0.2222\n",
      "Epoch 461/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.8582 - accuracy: 0.6538 - val_loss: 1.3748 - val_accuracy: 0.4444\n",
      "Epoch 462/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8606 - accuracy: 0.5385 - val_loss: 1.8156 - val_accuracy: 0.2222\n",
      "Epoch 463/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8688 - accuracy: 0.6154 - val_loss: 1.6174 - val_accuracy: 0.2222\n",
      "Epoch 464/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7844 - accuracy: 0.6410 - val_loss: 1.2643 - val_accuracy: 0.5556\n",
      "Epoch 465/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7995 - accuracy: 0.6282 - val_loss: 1.7837 - val_accuracy: 0.1111\n",
      "Epoch 466/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7941 - accuracy: 0.6410 - val_loss: 1.1730 - val_accuracy: 0.5556\n",
      "Epoch 467/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7773 - accuracy: 0.6538 - val_loss: 1.3733 - val_accuracy: 0.3333\n",
      "Epoch 468/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8496 - accuracy: 0.6538 - val_loss: 1.6443 - val_accuracy: 0.3333\n",
      "Epoch 469/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8457 - accuracy: 0.6410 - val_loss: 1.3574 - val_accuracy: 0.5556\n",
      "Epoch 470/1000\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.7996 - accuracy: 0.6538 - val_loss: 1.2778 - val_accuracy: 0.4444\n",
      "Epoch 471/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7774 - accuracy: 0.6282 - val_loss: 1.5343 - val_accuracy: 0.4444\n",
      "Epoch 472/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7201 - accuracy: 0.7179 - val_loss: 1.6470 - val_accuracy: 0.3333\n",
      "Epoch 473/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7598 - accuracy: 0.6538 - val_loss: 1.4608 - val_accuracy: 0.5556\n",
      "Epoch 474/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7335 - accuracy: 0.6538 - val_loss: 1.3456 - val_accuracy: 0.4444\n",
      "Epoch 475/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7467 - accuracy: 0.6667 - val_loss: 1.3412 - val_accuracy: 0.6667\n",
      "Epoch 476/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7581 - accuracy: 0.6923 - val_loss: 1.7222 - val_accuracy: 0.3333\n",
      "Epoch 477/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8277 - accuracy: 0.6026 - val_loss: 1.4501 - val_accuracy: 0.5556\n",
      "Epoch 478/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7316 - accuracy: 0.6538 - val_loss: 1.6095 - val_accuracy: 0.3333\n",
      "Epoch 479/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7716 - accuracy: 0.6410 - val_loss: 1.5848 - val_accuracy: 0.1111\n",
      "Epoch 480/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7354 - accuracy: 0.7308 - val_loss: 1.5881 - val_accuracy: 0.5556\n",
      "Epoch 481/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7541 - accuracy: 0.6538 - val_loss: 1.5556 - val_accuracy: 0.3333\n",
      "Epoch 482/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7253 - accuracy: 0.6667 - val_loss: 1.6649 - val_accuracy: 0.3333\n",
      "Epoch 483/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7931 - accuracy: 0.6026 - val_loss: 1.8355 - val_accuracy: 0.2222\n",
      "Epoch 484/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8509 - accuracy: 0.5897 - val_loss: 1.8619 - val_accuracy: 0.2222\n",
      "Epoch 485/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0071 - accuracy: 0.5897 - val_loss: 1.3442 - val_accuracy: 0.4444\n",
      "Epoch 486/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9309 - accuracy: 0.6282 - val_loss: 2.0611 - val_accuracy: 0.2222\n",
      "Epoch 487/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8022 - accuracy: 0.6538 - val_loss: 2.1176 - val_accuracy: 0.1111\n",
      "Epoch 488/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7823 - accuracy: 0.6282 - val_loss: 1.5253 - val_accuracy: 0.3333\n",
      "Epoch 489/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7931 - accuracy: 0.6154 - val_loss: 1.4874 - val_accuracy: 0.4444\n",
      "Epoch 490/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8394 - accuracy: 0.6410 - val_loss: 1.4622 - val_accuracy: 0.4444\n",
      "Epoch 491/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7571 - accuracy: 0.6154 - val_loss: 1.6865 - val_accuracy: 0.2222\n",
      "Epoch 492/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7535 - accuracy: 0.6410 - val_loss: 1.8446 - val_accuracy: 0.2222\n",
      "Epoch 493/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7083 - accuracy: 0.6667 - val_loss: 1.2865 - val_accuracy: 0.5556\n",
      "Epoch 494/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7023 - accuracy: 0.7179 - val_loss: 1.8816 - val_accuracy: 0.2222\n",
      "Epoch 495/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7445 - accuracy: 0.6923 - val_loss: 1.4948 - val_accuracy: 0.5556\n",
      "Epoch 496/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7585 - accuracy: 0.6410 - val_loss: 1.3416 - val_accuracy: 0.6667\n",
      "Epoch 497/1000\n",
      "78/78 [==============================] - 1s 18ms/step - loss: 0.7893 - accuracy: 0.6667 - val_loss: 1.5327 - val_accuracy: 0.4444\n",
      "Epoch 498/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7223 - accuracy: 0.7051 - val_loss: 1.3356 - val_accuracy: 0.5556\n",
      "Epoch 499/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7739 - accuracy: 0.6538 - val_loss: 2.1179 - val_accuracy: 0.1111\n",
      "Epoch 500/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7199 - accuracy: 0.6923 - val_loss: 1.4323 - val_accuracy: 0.4444\n",
      "Epoch 501/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7345 - accuracy: 0.7051 - val_loss: 1.6751 - val_accuracy: 0.3333\n",
      "Epoch 502/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8007 - accuracy: 0.6410 - val_loss: 1.9420 - val_accuracy: 0.2222\n",
      "Epoch 503/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7865 - accuracy: 0.6282 - val_loss: 1.2001 - val_accuracy: 0.5556\n",
      "Epoch 504/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.1771 - accuracy: 0.5385 - val_loss: 1.4402 - val_accuracy: 0.5556\n",
      "Epoch 505/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9652 - accuracy: 0.6154 - val_loss: 2.7099 - val_accuracy: 0.1111\n",
      "Epoch 506/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.8416 - accuracy: 0.6410 - val_loss: 1.8600 - val_accuracy: 0.4444\n",
      "Epoch 507/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8737 - accuracy: 0.5897 - val_loss: 2.3060 - val_accuracy: 0.1111\n",
      "Epoch 508/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8130 - accuracy: 0.6923 - val_loss: 1.6767 - val_accuracy: 0.2222\n",
      "Epoch 509/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7368 - accuracy: 0.7051 - val_loss: 1.2665 - val_accuracy: 0.6667\n",
      "Epoch 510/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8982 - accuracy: 0.5769 - val_loss: 1.7533 - val_accuracy: 0.3333\n",
      "Epoch 511/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7472 - accuracy: 0.6154 - val_loss: 1.2952 - val_accuracy: 0.5556\n",
      "Epoch 512/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7646 - accuracy: 0.6667 - val_loss: 1.7461 - val_accuracy: 0.3333\n",
      "Epoch 513/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8046 - accuracy: 0.5769 - val_loss: 1.7294 - val_accuracy: 0.3333\n",
      "Epoch 514/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7080 - accuracy: 0.7051 - val_loss: 1.3471 - val_accuracy: 0.5556\n",
      "Epoch 515/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.7495 - accuracy: 0.6538 - val_loss: 1.4551 - val_accuracy: 0.4444\n",
      "Epoch 516/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7177 - accuracy: 0.7436 - val_loss: 1.1340 - val_accuracy: 0.5556\n",
      "Epoch 517/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7584 - accuracy: 0.6282 - val_loss: 1.5041 - val_accuracy: 0.3333\n",
      "Epoch 518/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7637 - accuracy: 0.6795 - val_loss: 1.5014 - val_accuracy: 0.5556\n",
      "Epoch 519/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7022 - accuracy: 0.6923 - val_loss: 1.4590 - val_accuracy: 0.5556\n",
      "Epoch 520/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7772 - accuracy: 0.6538 - val_loss: 1.8785 - val_accuracy: 0.2222\n",
      "Epoch 521/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8513 - accuracy: 0.6026 - val_loss: 1.7119 - val_accuracy: 0.4444\n",
      "Epoch 522/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7290 - accuracy: 0.6795 - val_loss: 1.3435 - val_accuracy: 0.5556\n",
      "Epoch 523/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.6893 - accuracy: 0.6795 - val_loss: 1.2532 - val_accuracy: 0.5556\n",
      "Epoch 524/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7310 - accuracy: 0.6923 - val_loss: 2.2336 - val_accuracy: 0.2222\n",
      "Epoch 525/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8003 - accuracy: 0.6795 - val_loss: 1.5184 - val_accuracy: 0.5556\n",
      "Epoch 526/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7490 - accuracy: 0.6795 - val_loss: 1.7736 - val_accuracy: 0.2222\n",
      "Epoch 527/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7379 - accuracy: 0.6923 - val_loss: 1.6163 - val_accuracy: 0.4444\n",
      "Epoch 528/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7461 - accuracy: 0.6538 - val_loss: 1.9634 - val_accuracy: 0.1111\n",
      "Epoch 529/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7332 - accuracy: 0.6667 - val_loss: 1.4576 - val_accuracy: 0.6667\n",
      "Epoch 530/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7675 - accuracy: 0.6538 - val_loss: 1.5815 - val_accuracy: 0.3333\n",
      "Epoch 531/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7667 - accuracy: 0.7051 - val_loss: 2.3469 - val_accuracy: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7541 - accuracy: 0.6795 - val_loss: 1.4940 - val_accuracy: 0.5556\n",
      "Epoch 533/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.7166 - accuracy: 0.6923 - val_loss: 1.3272 - val_accuracy: 0.4444\n",
      "Epoch 534/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8049 - accuracy: 0.6154 - val_loss: 1.7963 - val_accuracy: 0.1111\n",
      "Epoch 535/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7152 - accuracy: 0.6923 - val_loss: 1.4768 - val_accuracy: 0.4444\n",
      "Epoch 536/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8042 - accuracy: 0.6667 - val_loss: 1.9439 - val_accuracy: 0.4444\n",
      "Epoch 537/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7624 - accuracy: 0.6923 - val_loss: 1.7937 - val_accuracy: 0.4444\n",
      "Epoch 538/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6914 - accuracy: 0.6667 - val_loss: 1.4104 - val_accuracy: 0.6667\n",
      "Epoch 539/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7482 - accuracy: 0.6538 - val_loss: 1.4843 - val_accuracy: 0.4444\n",
      "Epoch 540/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9405 - accuracy: 0.6026 - val_loss: 1.2279 - val_accuracy: 0.5556\n",
      "Epoch 541/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8569 - accuracy: 0.6667 - val_loss: 1.4119 - val_accuracy: 0.4444\n",
      "Epoch 542/1000\n",
      "78/78 [==============================] - 1s 17ms/step - loss: 0.7958 - accuracy: 0.6026 - val_loss: 1.8168 - val_accuracy: 0.2222\n",
      "Epoch 543/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7300 - accuracy: 0.6282 - val_loss: 1.6071 - val_accuracy: 0.4444\n",
      "Epoch 544/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7669 - accuracy: 0.6667 - val_loss: 1.8940 - val_accuracy: 0.2222\n",
      "Epoch 545/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7211 - accuracy: 0.6538 - val_loss: 1.4923 - val_accuracy: 0.4444\n",
      "Epoch 546/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7671 - accuracy: 0.6795 - val_loss: 1.4784 - val_accuracy: 0.4444\n",
      "Epoch 547/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7043 - accuracy: 0.7051 - val_loss: 1.2405 - val_accuracy: 0.5556\n",
      "Epoch 548/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.7738 - accuracy: 0.5897 - val_loss: 1.5528 - val_accuracy: 0.5556\n",
      "Epoch 549/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7457 - accuracy: 0.6667 - val_loss: 1.6422 - val_accuracy: 0.3333\n",
      "Epoch 550/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7602 - accuracy: 0.6667 - val_loss: 1.5969 - val_accuracy: 0.3333\n",
      "Epoch 551/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7696 - accuracy: 0.5897 - val_loss: 1.7081 - val_accuracy: 0.4444\n",
      "Epoch 552/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.6803 - accuracy: 0.7308 - val_loss: 1.6499 - val_accuracy: 0.4444\n",
      "Epoch 553/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7332 - accuracy: 0.6923 - val_loss: 1.3712 - val_accuracy: 0.5556\n",
      "Epoch 554/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7714 - accuracy: 0.7051 - val_loss: 1.8391 - val_accuracy: 0.3333\n",
      "Epoch 555/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7198 - accuracy: 0.6667 - val_loss: 1.6397 - val_accuracy: 0.5556\n",
      "Epoch 556/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7069 - accuracy: 0.6154 - val_loss: 1.3114 - val_accuracy: 0.5556\n",
      "Epoch 557/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9199 - accuracy: 0.6410 - val_loss: 1.8730 - val_accuracy: 0.2222\n",
      "Epoch 558/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7270 - accuracy: 0.6923 - val_loss: 1.5672 - val_accuracy: 0.4444\n",
      "Epoch 559/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7043 - accuracy: 0.7308 - val_loss: 1.7079 - val_accuracy: 0.3333\n",
      "Epoch 560/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7714 - accuracy: 0.6410 - val_loss: 1.5366 - val_accuracy: 0.1111\n",
      "Epoch 561/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7629 - accuracy: 0.6538 - val_loss: 1.8547 - val_accuracy: 0.4444\n",
      "Epoch 562/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7389 - accuracy: 0.6410 - val_loss: 1.2003 - val_accuracy: 0.4444\n",
      "Epoch 563/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7165 - accuracy: 0.6795 - val_loss: 2.3154 - val_accuracy: 0.1111\n",
      "Epoch 564/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7122 - accuracy: 0.6795 - val_loss: 2.0742 - val_accuracy: 0.2222\n",
      "Epoch 565/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7307 - accuracy: 0.6667 - val_loss: 1.5638 - val_accuracy: 0.5556\n",
      "Epoch 566/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7879 - accuracy: 0.6538 - val_loss: 1.8013 - val_accuracy: 0.2222\n",
      "Epoch 567/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7032 - accuracy: 0.6923 - val_loss: 1.6779 - val_accuracy: 0.3333\n",
      "Epoch 568/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7678 - accuracy: 0.6282 - val_loss: 1.4796 - val_accuracy: 0.4444\n",
      "Epoch 569/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7248 - accuracy: 0.6667 - val_loss: 1.5464 - val_accuracy: 0.4444\n",
      "Epoch 570/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7004 - accuracy: 0.7179 - val_loss: 2.0304 - val_accuracy: 0.1111\n",
      "Epoch 571/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.6936 - accuracy: 0.7436 - val_loss: 1.5036 - val_accuracy: 0.4444\n",
      "Epoch 572/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6994 - accuracy: 0.7308 - val_loss: 1.6315 - val_accuracy: 0.2222\n",
      "Epoch 573/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7315 - accuracy: 0.7051 - val_loss: 1.4227 - val_accuracy: 0.5556\n",
      "Epoch 574/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8944 - accuracy: 0.5513 - val_loss: 1.5092 - val_accuracy: 0.3333\n",
      "Epoch 575/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7866 - accuracy: 0.6538 - val_loss: 1.7525 - val_accuracy: 0.2222\n",
      "Epoch 576/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6956 - accuracy: 0.6667 - val_loss: 1.4823 - val_accuracy: 0.6667\n",
      "Epoch 577/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7805 - accuracy: 0.6667 - val_loss: 1.4819 - val_accuracy: 0.4444\n",
      "Epoch 578/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8154 - accuracy: 0.6410 - val_loss: 1.8713 - val_accuracy: 0.3333\n",
      "Epoch 579/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7479 - accuracy: 0.6410 - val_loss: 1.9479 - val_accuracy: 0.2222\n",
      "Epoch 580/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.7157 - accuracy: 0.7051 - val_loss: 1.6566 - val_accuracy: 0.3333\n",
      "Epoch 581/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7267 - accuracy: 0.6795 - val_loss: 1.8008 - val_accuracy: 0.3333\n",
      "Epoch 582/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7662 - accuracy: 0.6538 - val_loss: 1.8248 - val_accuracy: 0.4444\n",
      "Epoch 583/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6849 - accuracy: 0.6667 - val_loss: 1.7634 - val_accuracy: 0.2222\n",
      "Epoch 584/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7196 - accuracy: 0.6538 - val_loss: 1.9441 - val_accuracy: 0.1111\n",
      "Epoch 585/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7611 - accuracy: 0.6538 - val_loss: 1.6536 - val_accuracy: 0.4444\n",
      "Epoch 586/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6958 - accuracy: 0.7051 - val_loss: 1.5397 - val_accuracy: 0.4444\n",
      "Epoch 587/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6712 - accuracy: 0.7308 - val_loss: 1.4938 - val_accuracy: 0.5556\n",
      "Epoch 588/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.7546 - accuracy: 0.6923 - val_loss: 1.9691 - val_accuracy: 0.1111\n",
      "Epoch 589/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7640 - accuracy: 0.6667 - val_loss: 1.7357 - val_accuracy: 0.3333\n",
      "Epoch 590/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6910 - accuracy: 0.7564 - val_loss: 1.6215 - val_accuracy: 0.3333\n",
      "Epoch 591/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8073 - accuracy: 0.6282 - val_loss: 1.8801 - val_accuracy: 0.1111\n",
      "Epoch 592/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8221 - accuracy: 0.6282 - val_loss: 2.4660 - val_accuracy: 0.2222\n",
      "Epoch 593/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7886 - accuracy: 0.6282 - val_loss: 1.5718 - val_accuracy: 0.5556\n",
      "Epoch 594/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7524 - accuracy: 0.6154 - val_loss: 1.7376 - val_accuracy: 0.4444\n",
      "Epoch 595/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7137 - accuracy: 0.7051 - val_loss: 1.8183 - val_accuracy: 0.3333\n",
      "Epoch 596/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6615 - accuracy: 0.7308 - val_loss: 1.5934 - val_accuracy: 0.5556\n",
      "Epoch 597/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6920 - accuracy: 0.6923 - val_loss: 1.9495 - val_accuracy: 0.3333\n",
      "Epoch 598/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6715 - accuracy: 0.6795 - val_loss: 1.9551 - val_accuracy: 0.2222\n",
      "Epoch 599/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7134 - accuracy: 0.7436 - val_loss: 1.6589 - val_accuracy: 0.4444\n",
      "Epoch 600/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8071 - accuracy: 0.5897 - val_loss: 2.2383 - val_accuracy: 0.2222\n",
      "Epoch 601/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9417 - accuracy: 0.6154 - val_loss: 1.4388 - val_accuracy: 0.5556\n",
      "Epoch 602/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9870 - accuracy: 0.5769 - val_loss: 2.0550 - val_accuracy: 0.2222\n",
      "Epoch 603/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7683 - accuracy: 0.6538 - val_loss: 1.9334 - val_accuracy: 0.1111\n",
      "Epoch 604/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6897 - accuracy: 0.6923 - val_loss: 1.7255 - val_accuracy: 0.4444\n",
      "Epoch 605/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7024 - accuracy: 0.6795 - val_loss: 1.8384 - val_accuracy: 0.2222\n",
      "Epoch 606/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.7051 - val_loss: 1.9413 - val_accuracy: 0.2222\n",
      "Epoch 607/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7391 - accuracy: 0.6667 - val_loss: 1.6247 - val_accuracy: 0.5556\n",
      "Epoch 608/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.6715 - accuracy: 0.6667 - val_loss: 1.5743 - val_accuracy: 0.5556\n",
      "Epoch 609/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7528 - accuracy: 0.6538 - val_loss: 1.8972 - val_accuracy: 0.3333\n",
      "Epoch 610/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7219 - accuracy: 0.6410 - val_loss: 1.6522 - val_accuracy: 0.5556\n",
      "Epoch 611/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7106 - accuracy: 0.6667 - val_loss: 1.8944 - val_accuracy: 0.3333\n",
      "Epoch 612/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6839 - accuracy: 0.7308 - val_loss: 1.6523 - val_accuracy: 0.4444\n",
      "Epoch 613/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6692 - accuracy: 0.7051 - val_loss: 2.0277 - val_accuracy: 0.3333\n",
      "Epoch 614/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7808 - accuracy: 0.6538 - val_loss: 1.7102 - val_accuracy: 0.3333\n",
      "Epoch 615/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7673 - accuracy: 0.6410 - val_loss: 1.8531 - val_accuracy: 0.4444\n",
      "Epoch 616/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7819 - accuracy: 0.6410 - val_loss: 1.8839 - val_accuracy: 0.1111\n",
      "Epoch 617/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.7273 - accuracy: 0.6410 - val_loss: 1.7712 - val_accuracy: 0.3333\n",
      "Epoch 618/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6679 - accuracy: 0.6538 - val_loss: 1.6179 - val_accuracy: 0.4444\n",
      "Epoch 619/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7341 - accuracy: 0.6795 - val_loss: 1.5169 - val_accuracy: 0.4444\n",
      "Epoch 620/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6842 - accuracy: 0.7179 - val_loss: 1.5288 - val_accuracy: 0.4444\n",
      "Epoch 621/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6679 - accuracy: 0.6923 - val_loss: 1.9512 - val_accuracy: 0.1111\n",
      "Epoch 622/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7351 - accuracy: 0.6795 - val_loss: 1.9070 - val_accuracy: 0.2222\n",
      "Epoch 623/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7222 - accuracy: 0.6538 - val_loss: 1.5362 - val_accuracy: 0.4444\n",
      "Epoch 624/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7633 - accuracy: 0.6410 - val_loss: 1.9596 - val_accuracy: 0.1111\n",
      "Epoch 625/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.1597 - accuracy: 0.5513 - val_loss: 1.6796 - val_accuracy: 0.3333\n",
      "Epoch 626/1000\n",
      "78/78 [==============================] - 2s 24ms/step - loss: 0.9979 - accuracy: 0.5385 - val_loss: 1.8610 - val_accuracy: 0.2222\n",
      "Epoch 627/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7826 - accuracy: 0.6154 - val_loss: 1.4724 - val_accuracy: 0.5556\n",
      "Epoch 628/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7542 - accuracy: 0.6410 - val_loss: 1.6189 - val_accuracy: 0.4444\n",
      "Epoch 629/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6984 - accuracy: 0.6923 - val_loss: 1.8082 - val_accuracy: 0.1111\n",
      "Epoch 630/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.7692 - val_loss: 1.2745 - val_accuracy: 0.4444\n",
      "Epoch 631/1000\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.7586 - accuracy: 0.6410 - val_loss: 1.7022 - val_accuracy: 0.4444\n",
      "Epoch 632/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6815 - accuracy: 0.6923 - val_loss: 1.4655 - val_accuracy: 0.5556\n",
      "Epoch 633/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7191 - accuracy: 0.6410 - val_loss: 1.5121 - val_accuracy: 0.5556\n",
      "Epoch 634/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7663 - accuracy: 0.6282 - val_loss: 1.7840 - val_accuracy: 0.4444\n",
      "Epoch 635/1000\n",
      "78/78 [==============================] - 2s 19ms/step - loss: 0.7287 - accuracy: 0.6795 - val_loss: 1.6684 - val_accuracy: 0.3333\n",
      "Epoch 636/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7722 - accuracy: 0.6795 - val_loss: 1.8117 - val_accuracy: 0.2222\n",
      "Epoch 637/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6782 - accuracy: 0.7179 - val_loss: 1.9824 - val_accuracy: 0.2222\n",
      "Epoch 638/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7320 - accuracy: 0.6410 - val_loss: 1.5815 - val_accuracy: 0.5556\n",
      "Epoch 639/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7256 - accuracy: 0.6923 - val_loss: 1.5788 - val_accuracy: 0.5556\n",
      "Epoch 640/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6537 - accuracy: 0.7179 - val_loss: 1.6535 - val_accuracy: 0.5556\n",
      "Epoch 641/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6687 - accuracy: 0.7308 - val_loss: 1.6977 - val_accuracy: 0.3333\n",
      "Epoch 642/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7225 - accuracy: 0.6667 - val_loss: 1.7593 - val_accuracy: 0.3333\n",
      "Epoch 643/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8658 - accuracy: 0.6154 - val_loss: 1.7145 - val_accuracy: 0.4444\n",
      "Epoch 644/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7237 - accuracy: 0.6667 - val_loss: 1.7654 - val_accuracy: 0.4444\n",
      "Epoch 645/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6844 - accuracy: 0.6667 - val_loss: 1.6779 - val_accuracy: 0.4444\n",
      "Epoch 646/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7153 - accuracy: 0.6667 - val_loss: 1.7147 - val_accuracy: 0.5556\n",
      "Epoch 647/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6538 - accuracy: 0.7051 - val_loss: 1.5835 - val_accuracy: 0.4444\n",
      "Epoch 648/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7220 - accuracy: 0.6667 - val_loss: 1.7321 - val_accuracy: 0.4444\n",
      "Epoch 649/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7103 - accuracy: 0.6795 - val_loss: 2.0489 - val_accuracy: 0.3333\n",
      "Epoch 650/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7234 - accuracy: 0.7179 - val_loss: 1.8023 - val_accuracy: 0.4444\n",
      "Epoch 651/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7003 - accuracy: 0.6923 - val_loss: 2.5379 - val_accuracy: 0.1111\n",
      "Epoch 652/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.7454 - accuracy: 0.6026 - val_loss: 1.7686 - val_accuracy: 0.3333\n",
      "Epoch 653/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7829 - accuracy: 0.6538 - val_loss: 1.5547 - val_accuracy: 0.5556\n",
      "Epoch 654/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8299 - accuracy: 0.6282 - val_loss: 1.5656 - val_accuracy: 0.5556\n",
      "Epoch 655/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8633 - accuracy: 0.6538 - val_loss: 1.5366 - val_accuracy: 0.5556\n",
      "Epoch 656/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6862 - accuracy: 0.6923 - val_loss: 1.6914 - val_accuracy: 0.4444\n",
      "Epoch 657/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7460 - accuracy: 0.6667 - val_loss: 1.7751 - val_accuracy: 0.1111\n",
      "Epoch 658/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7105 - accuracy: 0.6538 - val_loss: 1.6870 - val_accuracy: 0.4444\n",
      "Epoch 659/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6737 - accuracy: 0.7179 - val_loss: 1.7906 - val_accuracy: 0.4444\n",
      "Epoch 660/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6803 - accuracy: 0.6923 - val_loss: 2.0970 - val_accuracy: 0.2222\n",
      "Epoch 661/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7222 - accuracy: 0.7308 - val_loss: 1.6934 - val_accuracy: 0.1111\n",
      "Epoch 662/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7455 - accuracy: 0.6923 - val_loss: 1.8697 - val_accuracy: 0.4444\n",
      "Epoch 663/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6570 - accuracy: 0.7051 - val_loss: 1.8481 - val_accuracy: 0.2222\n",
      "Epoch 664/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7322 - accuracy: 0.7179 - val_loss: 1.6720 - val_accuracy: 0.4444\n",
      "Epoch 665/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6812 - accuracy: 0.6795 - val_loss: 2.0354 - val_accuracy: 0.1111\n",
      "Epoch 666/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6535 - accuracy: 0.7308 - val_loss: 1.4529 - val_accuracy: 0.5556\n",
      "Epoch 667/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7688 - accuracy: 0.6410 - val_loss: 1.8652 - val_accuracy: 0.2222\n",
      "Epoch 668/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6928 - accuracy: 0.6923 - val_loss: 1.6756 - val_accuracy: 0.5556\n",
      "Epoch 669/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6838 - accuracy: 0.7179 - val_loss: 1.8874 - val_accuracy: 0.3333\n",
      "Epoch 670/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7660 - accuracy: 0.6667 - val_loss: 1.8372 - val_accuracy: 0.4444\n",
      "Epoch 671/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.7908 - accuracy: 0.6282 - val_loss: 1.8418 - val_accuracy: 0.2222\n",
      "Epoch 672/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7625 - accuracy: 0.6667 - val_loss: 1.8238 - val_accuracy: 0.4444\n",
      "Epoch 673/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7508 - accuracy: 0.6795 - val_loss: 1.9492 - val_accuracy: 0.4444\n",
      "Epoch 674/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6994 - accuracy: 0.6538 - val_loss: 1.6547 - val_accuracy: 0.4444\n",
      "Epoch 675/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7419 - accuracy: 0.6667 - val_loss: 1.5590 - val_accuracy: 0.4444\n",
      "Epoch 676/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6718 - accuracy: 0.6795 - val_loss: 2.0105 - val_accuracy: 0.1111\n",
      "Epoch 677/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6795 - accuracy: 0.7051 - val_loss: 1.6448 - val_accuracy: 0.5556\n",
      "Epoch 678/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6590 - accuracy: 0.6795 - val_loss: 1.7411 - val_accuracy: 0.4444\n",
      "Epoch 679/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6958 - accuracy: 0.7051 - val_loss: 1.6086 - val_accuracy: 0.5556\n",
      "Epoch 680/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7907 - accuracy: 0.6795 - val_loss: 1.6100 - val_accuracy: 0.4444\n",
      "Epoch 681/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7304 - accuracy: 0.6667 - val_loss: 1.6626 - val_accuracy: 0.3333\n",
      "Epoch 682/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7378 - accuracy: 0.7308 - val_loss: 1.6374 - val_accuracy: 0.4444\n",
      "Epoch 683/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.3745 - accuracy: 0.4872 - val_loss: 0.8615 - val_accuracy: 0.5556\n",
      "Epoch 684/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.4400 - accuracy: 0.3974 - val_loss: 0.9537 - val_accuracy: 0.5556\n",
      "Epoch 685/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.1931 - accuracy: 0.5000 - val_loss: 0.7394 - val_accuracy: 0.6667\n",
      "Epoch 686/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.2855 - accuracy: 0.5000 - val_loss: 1.2718 - val_accuracy: 0.4444\n",
      "Epoch 687/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.2043 - accuracy: 0.4872 - val_loss: 0.9069 - val_accuracy: 0.6667\n",
      "Epoch 688/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0772 - accuracy: 0.4744 - val_loss: 1.6148 - val_accuracy: 0.5556\n",
      "Epoch 689/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.1907 - accuracy: 0.5000 - val_loss: 0.7892 - val_accuracy: 0.5556\n",
      "Epoch 690/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.1819 - accuracy: 0.5256 - val_loss: 1.0335 - val_accuracy: 0.5556\n",
      "Epoch 691/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 1.1122 - accuracy: 0.5641 - val_loss: 1.0509 - val_accuracy: 0.4444\n",
      "Epoch 692/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0737 - accuracy: 0.5513 - val_loss: 0.8834 - val_accuracy: 0.6667\n",
      "Epoch 693/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0194 - accuracy: 0.5385 - val_loss: 1.4387 - val_accuracy: 0.3333\n",
      "Epoch 694/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9761 - accuracy: 0.5513 - val_loss: 0.7858 - val_accuracy: 0.6667\n",
      "Epoch 695/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9724 - accuracy: 0.5641 - val_loss: 1.0264 - val_accuracy: 0.5556\n",
      "Epoch 696/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9436 - accuracy: 0.6410 - val_loss: 1.1954 - val_accuracy: 0.4444\n",
      "Epoch 697/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0525 - accuracy: 0.5385 - val_loss: 0.9648 - val_accuracy: 0.4444\n",
      "Epoch 698/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9425 - accuracy: 0.6026 - val_loss: 1.0469 - val_accuracy: 0.4444\n",
      "Epoch 699/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0694 - accuracy: 0.5385 - val_loss: 1.1820 - val_accuracy: 0.3333\n",
      "Epoch 700/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.9486 - accuracy: 0.5897 - val_loss: 0.8856 - val_accuracy: 0.6667\n",
      "Epoch 701/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9184 - accuracy: 0.6026 - val_loss: 1.1337 - val_accuracy: 0.3333\n",
      "Epoch 702/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0028 - accuracy: 0.6154 - val_loss: 0.8325 - val_accuracy: 0.6667\n",
      "Epoch 703/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9472 - accuracy: 0.5897 - val_loss: 1.0081 - val_accuracy: 0.4444\n",
      "Epoch 704/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9035 - accuracy: 0.5897 - val_loss: 0.7627 - val_accuracy: 0.6667\n",
      "Epoch 705/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8711 - accuracy: 0.5513 - val_loss: 1.0831 - val_accuracy: 0.4444\n",
      "Epoch 706/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9032 - accuracy: 0.6026 - val_loss: 1.0449 - val_accuracy: 0.3333\n",
      "Epoch 707/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9754 - accuracy: 0.6154 - val_loss: 1.0567 - val_accuracy: 0.6667\n",
      "Epoch 708/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9168 - accuracy: 0.6026 - val_loss: 0.9932 - val_accuracy: 0.6667\n",
      "Epoch 709/1000\n",
      "78/78 [==============================] - 1s 15ms/step - loss: 0.8966 - accuracy: 0.6154 - val_loss: 0.9468 - val_accuracy: 0.6667\n",
      "Epoch 710/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9725 - accuracy: 0.5897 - val_loss: 1.0165 - val_accuracy: 0.6667\n",
      "Epoch 711/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9383 - accuracy: 0.5513 - val_loss: 1.3557 - val_accuracy: 0.3333\n",
      "Epoch 712/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 1.0379 - accuracy: 0.5256 - val_loss: 0.8524 - val_accuracy: 0.6667\n",
      "Epoch 713/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9980 - accuracy: 0.5513 - val_loss: 1.0594 - val_accuracy: 0.4444\n",
      "Epoch 714/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9825 - accuracy: 0.5641 - val_loss: 1.7718 - val_accuracy: 0.3333\n",
      "Epoch 715/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8898 - accuracy: 0.6026 - val_loss: 1.2374 - val_accuracy: 0.5556\n",
      "Epoch 716/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9352 - accuracy: 0.5641 - val_loss: 0.7176 - val_accuracy: 0.5556\n",
      "Epoch 717/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9523 - accuracy: 0.5513 - val_loss: 1.0623 - val_accuracy: 0.4444\n",
      "Epoch 718/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.9277 - accuracy: 0.5641 - val_loss: 1.0861 - val_accuracy: 0.3333\n",
      "Epoch 719/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9730 - accuracy: 0.5513 - val_loss: 1.2941 - val_accuracy: 0.2222\n",
      "Epoch 720/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8767 - accuracy: 0.6154 - val_loss: 1.0005 - val_accuracy: 0.4444\n",
      "Epoch 721/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8787 - accuracy: 0.6282 - val_loss: 1.1541 - val_accuracy: 0.3333\n",
      "Epoch 722/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9048 - accuracy: 0.5128 - val_loss: 1.2001 - val_accuracy: 0.5556\n",
      "Epoch 723/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9127 - accuracy: 0.5769 - val_loss: 0.8303 - val_accuracy: 0.6667\n",
      "Epoch 724/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8212 - accuracy: 0.6538 - val_loss: 1.0537 - val_accuracy: 0.5556\n",
      "Epoch 725/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8750 - accuracy: 0.6282 - val_loss: 0.9952 - val_accuracy: 0.6667\n",
      "Epoch 726/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8346 - accuracy: 0.6154 - val_loss: 1.1581 - val_accuracy: 0.2222\n",
      "Epoch 727/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.8608 - accuracy: 0.6154 - val_loss: 0.8392 - val_accuracy: 0.6667\n",
      "Epoch 728/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8574 - accuracy: 0.6410 - val_loss: 0.9051 - val_accuracy: 0.5556\n",
      "Epoch 729/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9008 - accuracy: 0.5897 - val_loss: 0.9348 - val_accuracy: 0.6667\n",
      "Epoch 730/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8822 - accuracy: 0.6282 - val_loss: 1.5504 - val_accuracy: 0.5556\n",
      "Epoch 731/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8992 - accuracy: 0.5897 - val_loss: 1.2537 - val_accuracy: 0.3333\n",
      "Epoch 732/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8768 - accuracy: 0.5897 - val_loss: 1.2171 - val_accuracy: 0.5556\n",
      "Epoch 733/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9312 - accuracy: 0.5513 - val_loss: 1.0105 - val_accuracy: 0.5556\n",
      "Epoch 734/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8283 - accuracy: 0.6154 - val_loss: 1.4424 - val_accuracy: 0.2222\n",
      "Epoch 735/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8511 - accuracy: 0.6026 - val_loss: 1.3470 - val_accuracy: 0.2222\n",
      "Epoch 736/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 1.0093 - accuracy: 0.5641 - val_loss: 0.9640 - val_accuracy: 0.6667\n",
      "Epoch 737/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8833 - accuracy: 0.6154 - val_loss: 1.2860 - val_accuracy: 0.6667\n",
      "Epoch 738/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8402 - accuracy: 0.6282 - val_loss: 1.0501 - val_accuracy: 0.8889\n",
      "Epoch 739/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9465 - accuracy: 0.5385 - val_loss: 1.2073 - val_accuracy: 0.5556\n",
      "Epoch 740/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9503 - accuracy: 0.5641 - val_loss: 1.1183 - val_accuracy: 0.6667\n",
      "Epoch 741/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8250 - accuracy: 0.5769 - val_loss: 1.5955 - val_accuracy: 0.3333\n",
      "Epoch 742/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8373 - accuracy: 0.6026 - val_loss: 1.2978 - val_accuracy: 0.3333\n",
      "Epoch 743/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8207 - accuracy: 0.6154 - val_loss: 1.8344 - val_accuracy: 0.2222\n",
      "Epoch 744/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.8897 - accuracy: 0.5128 - val_loss: 1.4785 - val_accuracy: 0.4444\n",
      "Epoch 745/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.9258 - accuracy: 0.5256 - val_loss: 1.4380 - val_accuracy: 0.4444\n",
      "Epoch 746/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8052 - accuracy: 0.6026 - val_loss: 1.4678 - val_accuracy: 0.5556\n",
      "Epoch 747/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8793 - accuracy: 0.6282 - val_loss: 1.3954 - val_accuracy: 0.3333\n",
      "Epoch 748/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9337 - accuracy: 0.5769 - val_loss: 1.2554 - val_accuracy: 0.7778\n",
      "Epoch 749/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8571 - accuracy: 0.6154 - val_loss: 1.3319 - val_accuracy: 0.5556\n",
      "Epoch 750/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.8328 - accuracy: 0.6154 - val_loss: 1.1267 - val_accuracy: 0.6667\n",
      "Epoch 751/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7841 - accuracy: 0.6282 - val_loss: 1.2795 - val_accuracy: 0.6667\n",
      "Epoch 752/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8305 - accuracy: 0.6026 - val_loss: 1.1876 - val_accuracy: 0.6667\n",
      "Epoch 753/1000\n",
      "78/78 [==============================] - 2s 21ms/step - loss: 0.8386 - accuracy: 0.5897 - val_loss: 1.1015 - val_accuracy: 0.6667\n",
      "Epoch 754/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9422 - accuracy: 0.6026 - val_loss: 0.9998 - val_accuracy: 0.7778\n",
      "Epoch 755/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8365 - accuracy: 0.5641 - val_loss: 1.4203 - val_accuracy: 0.6667\n",
      "Epoch 756/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8210 - accuracy: 0.5513 - val_loss: 1.4292 - val_accuracy: 0.3333\n",
      "Epoch 757/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8672 - accuracy: 0.6154 - val_loss: 1.8829 - val_accuracy: 0.3333\n",
      "Epoch 758/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9557 - accuracy: 0.5513 - val_loss: 1.4769 - val_accuracy: 0.7778\n",
      "Epoch 759/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8223 - accuracy: 0.6154 - val_loss: 1.2772 - val_accuracy: 0.6667\n",
      "Epoch 760/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8721 - accuracy: 0.5641 - val_loss: 1.4276 - val_accuracy: 0.5556\n",
      "Epoch 761/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8296 - accuracy: 0.5641 - val_loss: 1.5305 - val_accuracy: 0.5556\n",
      "Epoch 762/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8580 - accuracy: 0.5897 - val_loss: 1.6985 - val_accuracy: 0.3333\n",
      "Epoch 763/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7673 - accuracy: 0.5897 - val_loss: 1.6133 - val_accuracy: 0.3333\n",
      "Epoch 764/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8014 - accuracy: 0.6026 - val_loss: 1.2902 - val_accuracy: 0.5556\n",
      "Epoch 765/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8156 - accuracy: 0.5769 - val_loss: 1.5475 - val_accuracy: 0.6667\n",
      "Epoch 766/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8797 - accuracy: 0.5897 - val_loss: 1.2388 - val_accuracy: 0.6667\n",
      "Epoch 767/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8207 - accuracy: 0.5897 - val_loss: 1.3428 - val_accuracy: 0.5556\n",
      "Epoch 768/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8262 - accuracy: 0.6026 - val_loss: 1.4532 - val_accuracy: 0.4444\n",
      "Epoch 769/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7746 - accuracy: 0.6026 - val_loss: 1.5079 - val_accuracy: 0.2222\n",
      "Epoch 770/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7705 - accuracy: 0.6923 - val_loss: 1.5607 - val_accuracy: 0.3333\n",
      "Epoch 771/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7962 - accuracy: 0.6282 - val_loss: 1.4569 - val_accuracy: 0.6667\n",
      "Epoch 772/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7923 - accuracy: 0.6026 - val_loss: 1.2951 - val_accuracy: 0.6667\n",
      "Epoch 773/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8227 - accuracy: 0.6282 - val_loss: 1.8706 - val_accuracy: 0.3333\n",
      "Epoch 774/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9189 - accuracy: 0.5897 - val_loss: 1.5073 - val_accuracy: 0.4444\n",
      "Epoch 775/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7902 - accuracy: 0.6667 - val_loss: 1.2464 - val_accuracy: 0.5556\n",
      "Epoch 776/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8557 - accuracy: 0.5897 - val_loss: 1.4966 - val_accuracy: 0.2222\n",
      "Epoch 777/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8690 - accuracy: 0.5897 - val_loss: 1.6610 - val_accuracy: 0.2222\n",
      "Epoch 778/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9215 - accuracy: 0.6154 - val_loss: 1.4486 - val_accuracy: 0.5556\n",
      "Epoch 779/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7996 - accuracy: 0.6154 - val_loss: 1.1578 - val_accuracy: 0.7778\n",
      "Epoch 780/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.7627 - accuracy: 0.6154 - val_loss: 1.7054 - val_accuracy: 0.2222\n",
      "Epoch 781/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.7723 - accuracy: 0.6282 - val_loss: 1.6868 - val_accuracy: 0.3333\n",
      "Epoch 782/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7636 - accuracy: 0.6154 - val_loss: 1.4540 - val_accuracy: 0.6667\n",
      "Epoch 783/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7909 - accuracy: 0.6410 - val_loss: 1.7305 - val_accuracy: 0.3333\n",
      "Epoch 784/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8120 - accuracy: 0.5769 - val_loss: 1.0799 - val_accuracy: 0.7778\n",
      "Epoch 785/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7583 - accuracy: 0.6282 - val_loss: 1.4272 - val_accuracy: 0.5556\n",
      "Epoch 786/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7727 - accuracy: 0.6154 - val_loss: 1.5153 - val_accuracy: 0.5556\n",
      "Epoch 787/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8176 - accuracy: 0.5897 - val_loss: 1.8942 - val_accuracy: 0.2222\n",
      "Epoch 788/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7844 - accuracy: 0.6154 - val_loss: 1.5778 - val_accuracy: 0.5556\n",
      "Epoch 789/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8020 - accuracy: 0.6282 - val_loss: 1.4470 - val_accuracy: 0.6667\n",
      "Epoch 790/1000\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 0.8121 - accuracy: 0.5769 - val_loss: 1.4333 - val_accuracy: 0.6667\n",
      "Epoch 791/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7783 - accuracy: 0.6026 - val_loss: 1.9623 - val_accuracy: 0.3333\n",
      "Epoch 792/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8223 - accuracy: 0.6154 - val_loss: 1.4600 - val_accuracy: 0.4444\n",
      "Epoch 793/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7792 - accuracy: 0.6795 - val_loss: 1.7634 - val_accuracy: 0.2222\n",
      "Epoch 794/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8532 - accuracy: 0.5897 - val_loss: 1.3112 - val_accuracy: 0.5556\n",
      "Epoch 795/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8326 - accuracy: 0.6154 - val_loss: 1.4311 - val_accuracy: 0.4444\n",
      "Epoch 796/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8569 - accuracy: 0.6026 - val_loss: 1.5216 - val_accuracy: 0.4444\n",
      "Epoch 797/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8033 - accuracy: 0.6026 - val_loss: 1.3955 - val_accuracy: 0.5556\n",
      "Epoch 798/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8071 - accuracy: 0.6538 - val_loss: 1.7595 - val_accuracy: 0.2222\n",
      "Epoch 799/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.8250 - accuracy: 0.5897 - val_loss: 1.7473 - val_accuracy: 0.6667\n",
      "Epoch 800/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8269 - accuracy: 0.5897 - val_loss: 1.4640 - val_accuracy: 0.4444\n",
      "Epoch 801/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8224 - accuracy: 0.6282 - val_loss: 0.9306 - val_accuracy: 0.7778\n",
      "Epoch 802/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8816 - accuracy: 0.5897 - val_loss: 1.4162 - val_accuracy: 0.5556\n",
      "Epoch 803/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7997 - accuracy: 0.6282 - val_loss: 1.5881 - val_accuracy: 0.4444\n",
      "Epoch 804/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8497 - accuracy: 0.6795 - val_loss: 1.1336 - val_accuracy: 0.6667\n",
      "Epoch 805/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8059 - accuracy: 0.6410 - val_loss: 1.4311 - val_accuracy: 0.4444\n",
      "Epoch 806/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8781 - accuracy: 0.6154 - val_loss: 1.6042 - val_accuracy: 0.5556\n",
      "Epoch 807/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7984 - accuracy: 0.6154 - val_loss: 1.6765 - val_accuracy: 0.1111\n",
      "Epoch 808/1000\n",
      "78/78 [==============================] - 1s 19ms/step - loss: 0.8985 - accuracy: 0.6026 - val_loss: 1.3435 - val_accuracy: 0.6667\n",
      "Epoch 809/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7914 - accuracy: 0.6154 - val_loss: 1.8589 - val_accuracy: 0.1111\n",
      "Epoch 810/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7904 - accuracy: 0.6282 - val_loss: 1.6937 - val_accuracy: 0.3333\n",
      "Epoch 811/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7934 - accuracy: 0.6154 - val_loss: 1.3738 - val_accuracy: 0.2222\n",
      "Epoch 812/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7923 - accuracy: 0.5769 - val_loss: 1.1917 - val_accuracy: 0.6667\n",
      "Epoch 813/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7497 - accuracy: 0.6538 - val_loss: 1.7413 - val_accuracy: 0.2222\n",
      "Epoch 814/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8090 - accuracy: 0.6282 - val_loss: 1.7162 - val_accuracy: 0.4444\n",
      "Epoch 815/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7700 - accuracy: 0.6410 - val_loss: 2.2464 - val_accuracy: 0.3333\n",
      "Epoch 816/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7768 - accuracy: 0.6282 - val_loss: 1.8207 - val_accuracy: 0.5556\n",
      "Epoch 817/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7729 - accuracy: 0.6282 - val_loss: 1.9166 - val_accuracy: 0.4444\n",
      "Epoch 818/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7894 - accuracy: 0.6923 - val_loss: 1.4579 - val_accuracy: 0.4444\n",
      "Epoch 819/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7536 - accuracy: 0.6282 - val_loss: 1.4225 - val_accuracy: 0.4444\n",
      "Epoch 820/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7285 - accuracy: 0.6410 - val_loss: 1.5219 - val_accuracy: 0.1111\n",
      "Epoch 821/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7991 - accuracy: 0.6026 - val_loss: 1.2983 - val_accuracy: 0.5556\n",
      "Epoch 822/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8006 - accuracy: 0.6026 - val_loss: 1.8212 - val_accuracy: 0.2222\n",
      "Epoch 823/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7730 - accuracy: 0.6410 - val_loss: 1.5741 - val_accuracy: 0.4444\n",
      "Epoch 824/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8261 - accuracy: 0.6154 - val_loss: 1.1505 - val_accuracy: 0.5556\n",
      "Epoch 825/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8599 - accuracy: 0.6154 - val_loss: 1.6667 - val_accuracy: 0.4444\n",
      "Epoch 826/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7376 - accuracy: 0.6667 - val_loss: 1.7066 - val_accuracy: 0.4444\n",
      "Epoch 827/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7580 - accuracy: 0.6667 - val_loss: 1.6598 - val_accuracy: 0.4444\n",
      "Epoch 828/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7538 - accuracy: 0.6667 - val_loss: 1.5587 - val_accuracy: 0.4444\n",
      "Epoch 829/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7066 - accuracy: 0.6667 - val_loss: 1.5485 - val_accuracy: 0.4444\n",
      "Epoch 830/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7255 - accuracy: 0.6795 - val_loss: 1.7849 - val_accuracy: 0.5556\n",
      "Epoch 831/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7210 - accuracy: 0.6282 - val_loss: 1.6171 - val_accuracy: 0.3333\n",
      "Epoch 832/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7808 - accuracy: 0.6026 - val_loss: 1.5799 - val_accuracy: 0.5556\n",
      "Epoch 833/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7896 - accuracy: 0.6667 - val_loss: 1.4259 - val_accuracy: 0.6667\n",
      "Epoch 834/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.9365 - accuracy: 0.5513 - val_loss: 1.5922 - val_accuracy: 0.2222\n",
      "Epoch 835/1000\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.8941 - accuracy: 0.5769 - val_loss: 1.3536 - val_accuracy: 0.3333\n",
      "Epoch 836/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8211 - accuracy: 0.6538 - val_loss: 1.7920 - val_accuracy: 0.1111\n",
      "Epoch 837/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7628 - accuracy: 0.6282 - val_loss: 1.5488 - val_accuracy: 0.6667\n",
      "Epoch 838/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8145 - accuracy: 0.6410 - val_loss: 1.5947 - val_accuracy: 0.4444\n",
      "Epoch 839/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7346 - accuracy: 0.6410 - val_loss: 1.4936 - val_accuracy: 0.2222\n",
      "Epoch 840/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7786 - accuracy: 0.6410 - val_loss: 1.5135 - val_accuracy: 0.3333\n",
      "Epoch 841/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7560 - accuracy: 0.6538 - val_loss: 1.1133 - val_accuracy: 0.5556\n",
      "Epoch 842/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7993 - accuracy: 0.5897 - val_loss: 1.3607 - val_accuracy: 0.5556\n",
      "Epoch 843/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7999 - accuracy: 0.5897 - val_loss: 1.5119 - val_accuracy: 0.6667\n",
      "Epoch 844/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7982 - accuracy: 0.6026 - val_loss: 1.4538 - val_accuracy: 0.5556\n",
      "Epoch 845/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8188 - accuracy: 0.6154 - val_loss: 1.8874 - val_accuracy: 0.1111\n",
      "Epoch 846/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6882 - accuracy: 0.6410 - val_loss: 1.4073 - val_accuracy: 0.5556\n",
      "Epoch 847/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6775 - accuracy: 0.6410 - val_loss: 1.6039 - val_accuracy: 0.2222\n",
      "Epoch 848/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6795 - accuracy: 0.7051 - val_loss: 1.4624 - val_accuracy: 0.6667\n",
      "Epoch 849/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7193 - accuracy: 0.6026 - val_loss: 1.7815 - val_accuracy: 0.2222\n",
      "Epoch 850/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7779 - accuracy: 0.6410 - val_loss: 2.0028 - val_accuracy: 0.4444\n",
      "Epoch 851/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7201 - accuracy: 0.6923 - val_loss: 1.8594 - val_accuracy: 0.3333\n",
      "Epoch 852/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7721 - accuracy: 0.6026 - val_loss: 1.8849 - val_accuracy: 0.2222\n",
      "Epoch 853/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6880 - accuracy: 0.6410 - val_loss: 1.5550 - val_accuracy: 0.4444\n",
      "Epoch 854/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7535 - accuracy: 0.6282 - val_loss: 1.6989 - val_accuracy: 0.4444\n",
      "Epoch 855/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7344 - accuracy: 0.6538 - val_loss: 1.7949 - val_accuracy: 0.4444\n",
      "Epoch 856/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8746 - accuracy: 0.5641 - val_loss: 1.6212 - val_accuracy: 0.4444\n",
      "Epoch 857/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7255 - accuracy: 0.6026 - val_loss: 1.8927 - val_accuracy: 0.2222\n",
      "Epoch 858/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7248 - accuracy: 0.6795 - val_loss: 1.8309 - val_accuracy: 0.3333\n",
      "Epoch 859/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7071 - accuracy: 0.6282 - val_loss: 1.6923 - val_accuracy: 0.4444\n",
      "Epoch 860/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7776 - accuracy: 0.6154 - val_loss: 1.9558 - val_accuracy: 0.1111\n",
      "Epoch 861/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7111 - accuracy: 0.6538 - val_loss: 1.7432 - val_accuracy: 0.4444\n",
      "Epoch 862/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7951 - accuracy: 0.6154 - val_loss: 1.4848 - val_accuracy: 0.5556\n",
      "Epoch 863/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.8458 - accuracy: 0.5641 - val_loss: 1.6484 - val_accuracy: 0.3333\n",
      "Epoch 864/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7804 - accuracy: 0.6154 - val_loss: 2.2144 - val_accuracy: 0.2222\n",
      "Epoch 865/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7639 - accuracy: 0.5897 - val_loss: 1.7322 - val_accuracy: 0.1111\n",
      "Epoch 866/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7819 - accuracy: 0.6667 - val_loss: 1.6447 - val_accuracy: 0.2222\n",
      "Epoch 867/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7032 - accuracy: 0.7051 - val_loss: 2.2697 - val_accuracy: 0.2222\n",
      "Epoch 868/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7234 - accuracy: 0.6538 - val_loss: 1.7238 - val_accuracy: 0.3333\n",
      "Epoch 869/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8057 - accuracy: 0.6667 - val_loss: 1.5601 - val_accuracy: 0.4444\n",
      "Epoch 870/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6968 - accuracy: 0.6795 - val_loss: 1.8281 - val_accuracy: 0.2222\n",
      "Epoch 871/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7156 - accuracy: 0.6410 - val_loss: 1.8401 - val_accuracy: 0.3333\n",
      "Epoch 872/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7376 - accuracy: 0.6282 - val_loss: 1.6196 - val_accuracy: 0.4444\n",
      "Epoch 873/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8267 - accuracy: 0.6282 - val_loss: 1.7201 - val_accuracy: 0.3333\n",
      "Epoch 874/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7193 - accuracy: 0.6923 - val_loss: 1.7126 - val_accuracy: 0.4444\n",
      "Epoch 875/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8290 - accuracy: 0.5897 - val_loss: 1.8739 - val_accuracy: 0.5556\n",
      "Epoch 876/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8774 - accuracy: 0.6282 - val_loss: 1.5660 - val_accuracy: 0.4444\n",
      "Epoch 877/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8171 - accuracy: 0.5769 - val_loss: 1.8552 - val_accuracy: 0.4444\n",
      "Epoch 878/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7193 - accuracy: 0.6026 - val_loss: 1.8773 - val_accuracy: 0.1111\n",
      "Epoch 879/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8034 - accuracy: 0.6026 - val_loss: 1.6949 - val_accuracy: 0.4444\n",
      "Epoch 880/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8229 - accuracy: 0.6154 - val_loss: 2.0863 - val_accuracy: 0.1111\n",
      "Epoch 881/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8858 - accuracy: 0.6282 - val_loss: 1.6722 - val_accuracy: 0.6667\n",
      "Epoch 882/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.7187 - accuracy: 0.6410 - val_loss: 2.0728 - val_accuracy: 0.2222\n",
      "Epoch 883/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7256 - accuracy: 0.6538 - val_loss: 1.8136 - val_accuracy: 0.5556\n",
      "Epoch 884/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6955 - accuracy: 0.6154 - val_loss: 1.9242 - val_accuracy: 0.4444\n",
      "Epoch 885/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.6786 - accuracy: 0.6538 - val_loss: 1.8717 - val_accuracy: 0.3333\n",
      "Epoch 886/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7251 - accuracy: 0.6410 - val_loss: 1.6458 - val_accuracy: 0.5556\n",
      "Epoch 887/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6796 - accuracy: 0.6667 - val_loss: 1.4053 - val_accuracy: 0.6667\n",
      "Epoch 888/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8170 - accuracy: 0.6410 - val_loss: 1.7701 - val_accuracy: 0.3333\n",
      "Epoch 889/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.7772 - accuracy: 0.5769 - val_loss: 1.8697 - val_accuracy: 0.1111\n",
      "Epoch 890/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.7952 - accuracy: 0.6026 - val_loss: 2.2069 - val_accuracy: 0.1111\n",
      "Epoch 891/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7080 - accuracy: 0.6410 - val_loss: 1.9780 - val_accuracy: 0.3333\n",
      "Epoch 892/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7712 - accuracy: 0.6410 - val_loss: 2.0529 - val_accuracy: 0.1111\n",
      "Epoch 893/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7843 - accuracy: 0.6795 - val_loss: 1.7866 - val_accuracy: 0.3333\n",
      "Epoch 894/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7884 - accuracy: 0.6282 - val_loss: 2.0730 - val_accuracy: 0.2222\n",
      "Epoch 895/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7829 - accuracy: 0.6410 - val_loss: 2.0625 - val_accuracy: 0.1111\n",
      "Epoch 896/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7257 - accuracy: 0.6923 - val_loss: 1.7321 - val_accuracy: 0.4444\n",
      "Epoch 897/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8315 - accuracy: 0.6154 - val_loss: 1.5898 - val_accuracy: 0.4444\n",
      "Epoch 898/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7133 - accuracy: 0.6795 - val_loss: 1.9863 - val_accuracy: 0.3333\n",
      "Epoch 899/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7139 - accuracy: 0.6410 - val_loss: 1.8111 - val_accuracy: 0.2222\n",
      "Epoch 900/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7029 - accuracy: 0.6410 - val_loss: 1.9315 - val_accuracy: 0.1111\n",
      "Epoch 901/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6725 - accuracy: 0.7051 - val_loss: 1.9550 - val_accuracy: 0.2222\n",
      "Epoch 902/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7186 - accuracy: 0.6538 - val_loss: 2.1143 - val_accuracy: 0.1111\n",
      "Epoch 903/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6684 - accuracy: 0.7179 - val_loss: 1.6769 - val_accuracy: 0.2222\n",
      "Epoch 904/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7546 - accuracy: 0.6667 - val_loss: 1.8282 - val_accuracy: 0.1111\n",
      "Epoch 905/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7188 - accuracy: 0.6410 - val_loss: 1.7529 - val_accuracy: 0.1111\n",
      "Epoch 906/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7113 - accuracy: 0.6538 - val_loss: 1.4098 - val_accuracy: 0.5556\n",
      "Epoch 907/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6744 - accuracy: 0.6410 - val_loss: 1.9030 - val_accuracy: 0.4444\n",
      "Epoch 908/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7915 - accuracy: 0.6282 - val_loss: 1.6541 - val_accuracy: 0.3333\n",
      "Epoch 909/1000\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 0.7401 - accuracy: 0.6282 - val_loss: 1.6323 - val_accuracy: 0.6667\n",
      "Epoch 910/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6485 - accuracy: 0.7051 - val_loss: 2.0875 - val_accuracy: 0.3333\n",
      "Epoch 911/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7256 - accuracy: 0.6154 - val_loss: 1.9475 - val_accuracy: 0.2222\n",
      "Epoch 912/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7308 - accuracy: 0.6154 - val_loss: 1.6097 - val_accuracy: 0.3333\n",
      "Epoch 913/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7217 - accuracy: 0.6410 - val_loss: 1.6980 - val_accuracy: 0.2222\n",
      "Epoch 914/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6673 - accuracy: 0.6795 - val_loss: 1.8068 - val_accuracy: 0.4444\n",
      "Epoch 915/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6539 - accuracy: 0.6923 - val_loss: 1.7262 - val_accuracy: 0.4444\n",
      "Epoch 916/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7008 - accuracy: 0.6923 - val_loss: 2.3437 - val_accuracy: 0.1111\n",
      "Epoch 917/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6729 - accuracy: 0.6667 - val_loss: 1.5845 - val_accuracy: 0.5556\n",
      "Epoch 918/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6724 - accuracy: 0.6667 - val_loss: 1.9657 - val_accuracy: 0.1111\n",
      "Epoch 919/1000\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.6955 - accuracy: 0.6410 - val_loss: 1.9599 - val_accuracy: 0.4444\n",
      "Epoch 920/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6684 - accuracy: 0.6923 - val_loss: 1.7371 - val_accuracy: 0.3333\n",
      "Epoch 921/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6491 - accuracy: 0.6923 - val_loss: 1.9883 - val_accuracy: 0.2222\n",
      "Epoch 922/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7033 - accuracy: 0.6795 - val_loss: 1.7290 - val_accuracy: 0.5556\n",
      "Epoch 923/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6631 - accuracy: 0.6538 - val_loss: 1.8195 - val_accuracy: 0.5556\n",
      "Epoch 924/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6935 - accuracy: 0.6795 - val_loss: 1.8369 - val_accuracy: 0.2222\n",
      "Epoch 925/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9009 - accuracy: 0.6282 - val_loss: 2.1291 - val_accuracy: 0.1111\n",
      "Epoch 926/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6716 - accuracy: 0.6538 - val_loss: 1.7039 - val_accuracy: 0.4444\n",
      "Epoch 927/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7564 - accuracy: 0.6154 - val_loss: 2.1869 - val_accuracy: 0.1111\n",
      "Epoch 928/1000\n",
      "78/78 [==============================] - 1s 11ms/step - loss: 0.6818 - accuracy: 0.6667 - val_loss: 1.5934 - val_accuracy: 0.6667\n",
      "Epoch 929/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6499 - accuracy: 0.6923 - val_loss: 1.4959 - val_accuracy: 0.5556\n",
      "Epoch 930/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7571 - accuracy: 0.6538 - val_loss: 1.9842 - val_accuracy: 0.2222\n",
      "Epoch 931/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7175 - accuracy: 0.6538 - val_loss: 1.7681 - val_accuracy: 0.1111\n",
      "Epoch 932/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7028 - accuracy: 0.6667 - val_loss: 1.9055 - val_accuracy: 0.5556\n",
      "Epoch 933/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6951 - accuracy: 0.6410 - val_loss: 1.7618 - val_accuracy: 0.1111\n",
      "Epoch 934/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.7604 - accuracy: 0.6410 - val_loss: 1.2752 - val_accuracy: 0.5556\n",
      "Epoch 935/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6658 - accuracy: 0.7051 - val_loss: 1.7201 - val_accuracy: 0.5556\n",
      "Epoch 936/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6077 - accuracy: 0.7179 - val_loss: 2.0010 - val_accuracy: 0.3333\n",
      "Epoch 937/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.6532 - accuracy: 0.6667 - val_loss: 1.8895 - val_accuracy: 0.4444\n",
      "Epoch 938/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6662 - accuracy: 0.6667 - val_loss: 1.9523 - val_accuracy: 0.1111\n",
      "Epoch 939/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7111 - accuracy: 0.6410 - val_loss: 1.8140 - val_accuracy: 0.2222\n",
      "Epoch 940/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6564 - accuracy: 0.6795 - val_loss: 1.9978 - val_accuracy: 0.1111\n",
      "Epoch 941/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7021 - accuracy: 0.7308 - val_loss: 1.8242 - val_accuracy: 0.4444\n",
      "Epoch 942/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6640 - accuracy: 0.6923 - val_loss: 1.8388 - val_accuracy: 0.3333\n",
      "Epoch 943/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6349 - accuracy: 0.6795 - val_loss: 2.1819 - val_accuracy: 0.1111\n",
      "Epoch 944/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.6538 - accuracy: 0.6795 - val_loss: 1.6418 - val_accuracy: 0.4444\n",
      "Epoch 945/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6739 - accuracy: 0.6795 - val_loss: 1.8734 - val_accuracy: 0.4444\n",
      "Epoch 946/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7466 - accuracy: 0.6410 - val_loss: 2.1007 - val_accuracy: 0.1111\n",
      "Epoch 947/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7109 - accuracy: 0.6795 - val_loss: 1.8881 - val_accuracy: 0.3333\n",
      "Epoch 948/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6233 - accuracy: 0.6667 - val_loss: 1.7229 - val_accuracy: 0.2222\n",
      "Epoch 949/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6793 - accuracy: 0.6795 - val_loss: 2.0858 - val_accuracy: 0.3333\n",
      "Epoch 950/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7289 - accuracy: 0.5897 - val_loss: 1.8557 - val_accuracy: 0.5556\n",
      "Epoch 951/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7181 - accuracy: 0.6410 - val_loss: 1.7364 - val_accuracy: 0.4444\n",
      "Epoch 952/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7234 - accuracy: 0.6538 - val_loss: 1.5753 - val_accuracy: 0.4444\n",
      "Epoch 953/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9401 - accuracy: 0.6026 - val_loss: 2.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 954/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7816 - accuracy: 0.6667 - val_loss: 1.8980 - val_accuracy: 0.3333\n",
      "Epoch 955/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7759 - accuracy: 0.6282 - val_loss: 1.8528 - val_accuracy: 0.3333\n",
      "Epoch 956/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.6731 - accuracy: 0.6538 - val_loss: 2.4653 - val_accuracy: 0.1111\n",
      "Epoch 957/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8059 - accuracy: 0.5769 - val_loss: 2.2706 - val_accuracy: 0.1111\n",
      "Epoch 958/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6565 - accuracy: 0.6795 - val_loss: 2.0146 - val_accuracy: 0.4444\n",
      "Epoch 959/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.5967 - accuracy: 0.7308 - val_loss: 1.8782 - val_accuracy: 0.1111\n",
      "Epoch 960/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7146 - accuracy: 0.6410 - val_loss: 1.5612 - val_accuracy: 0.4444\n",
      "Epoch 961/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6404 - accuracy: 0.7564 - val_loss: 1.9425 - val_accuracy: 0.5556\n",
      "Epoch 962/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7305 - accuracy: 0.6154 - val_loss: 2.2890 - val_accuracy: 0.1111\n",
      "Epoch 963/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6841 - accuracy: 0.6795 - val_loss: 1.9267 - val_accuracy: 0.4444\n",
      "Epoch 964/1000\n",
      "78/78 [==============================] - 1s 8ms/step - loss: 0.7355 - accuracy: 0.6282 - val_loss: 2.2166 - val_accuracy: 0.1111\n",
      "Epoch 965/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.6470 - accuracy: 0.7179 - val_loss: 1.8636 - val_accuracy: 0.3333\n",
      "Epoch 966/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6533 - accuracy: 0.6667 - val_loss: 2.0151 - val_accuracy: 0.2222\n",
      "Epoch 967/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6566 - accuracy: 0.6795 - val_loss: 1.8182 - val_accuracy: 0.5556\n",
      "Epoch 968/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6003 - accuracy: 0.7436 - val_loss: 2.2088 - val_accuracy: 0.4444\n",
      "Epoch 969/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.9094 - accuracy: 0.5897 - val_loss: 2.7447 - val_accuracy: 0.1111\n",
      "Epoch 970/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.8034 - accuracy: 0.6667 - val_loss: 2.3207 - val_accuracy: 0.3333\n",
      "Epoch 971/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6901 - accuracy: 0.6538 - val_loss: 1.9200 - val_accuracy: 0.2222\n",
      "Epoch 972/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6534 - accuracy: 0.6538 - val_loss: 2.3173 - val_accuracy: 0.1111\n",
      "Epoch 973/1000\n",
      "78/78 [==============================] - 1s 12ms/step - loss: 0.6387 - accuracy: 0.7179 - val_loss: 1.8996 - val_accuracy: 0.2222\n",
      "Epoch 974/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6996 - accuracy: 0.6795 - val_loss: 2.3731 - val_accuracy: 0.1111\n",
      "Epoch 975/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7331 - accuracy: 0.6667 - val_loss: 1.8530 - val_accuracy: 0.3333\n",
      "Epoch 976/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6662 - accuracy: 0.6923 - val_loss: 2.3152 - val_accuracy: 0.1111\n",
      "Epoch 977/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7405 - accuracy: 0.6538 - val_loss: 1.5165 - val_accuracy: 0.5556\n",
      "Epoch 978/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7896 - accuracy: 0.6410 - val_loss: 2.2817 - val_accuracy: 0.1111\n",
      "Epoch 979/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6509 - accuracy: 0.6795 - val_loss: 2.1684 - val_accuracy: 0.1111\n",
      "Epoch 980/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7112 - accuracy: 0.6795 - val_loss: 1.6684 - val_accuracy: 0.4444\n",
      "Epoch 981/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6045 - accuracy: 0.7051 - val_loss: 1.8855 - val_accuracy: 0.3333\n",
      "Epoch 982/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6440 - accuracy: 0.6923 - val_loss: 1.3997 - val_accuracy: 0.6667\n",
      "Epoch 983/1000\n",
      "78/78 [==============================] - 1s 14ms/step - loss: 0.7028 - accuracy: 0.6795 - val_loss: 2.2283 - val_accuracy: 0.1111\n",
      "Epoch 984/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6832 - accuracy: 0.6795 - val_loss: 2.2641 - val_accuracy: 0.1111\n",
      "Epoch 985/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6787 - accuracy: 0.6667 - val_loss: 2.2443 - val_accuracy: 0.1111\n",
      "Epoch 986/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6090 - accuracy: 0.7308 - val_loss: 1.7434 - val_accuracy: 0.6667\n",
      "Epoch 987/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6597 - accuracy: 0.6795 - val_loss: 2.1522 - val_accuracy: 0.1111\n",
      "Epoch 988/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6292 - accuracy: 0.7179 - val_loss: 1.9679 - val_accuracy: 0.2222\n",
      "Epoch 989/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6967 - accuracy: 0.6538 - val_loss: 2.1843 - val_accuracy: 0.1111\n",
      "Epoch 990/1000\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 0.6424 - accuracy: 0.6795 - val_loss: 1.9075 - val_accuracy: 0.1111\n",
      "Epoch 991/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6741 - accuracy: 0.6410 - val_loss: 1.8199 - val_accuracy: 0.2222\n",
      "Epoch 992/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6094 - accuracy: 0.6923 - val_loss: 1.9783 - val_accuracy: 0.3333\n",
      "Epoch 993/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6625 - accuracy: 0.7051 - val_loss: 1.9053 - val_accuracy: 0.5556\n",
      "Epoch 994/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7530 - accuracy: 0.6667 - val_loss: 1.9318 - val_accuracy: 0.3333\n",
      "Epoch 995/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6118 - accuracy: 0.7051 - val_loss: 2.1168 - val_accuracy: 0.1111\n",
      "Epoch 996/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.7020 - accuracy: 0.6795 - val_loss: 2.3577 - val_accuracy: 0.1111\n",
      "Epoch 997/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6888 - accuracy: 0.6410 - val_loss: 1.5955 - val_accuracy: 0.3333\n",
      "Epoch 998/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6511 - accuracy: 0.6410 - val_loss: 2.0519 - val_accuracy: 0.3333\n",
      "Epoch 999/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6716 - accuracy: 0.6538 - val_loss: 1.9090 - val_accuracy: 0.3333\n",
      "Epoch 1000/1000\n",
      "78/78 [==============================] - 1s 9ms/step - loss: 0.6915 - accuracy: 0.6667 - val_loss: 2.2073 - val_accuracy: 0.1111\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=1, validation_data=(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1391031742095947, 0.4444444477558136]\n",
      "Accuracy: 0.792% (+/-0.347)\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(scores)\n",
    "m, s = np.mean(scores), np.std(scores)\n",
    "print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['accuracy'], label='accuracy')\n",
    "  plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[2:14], kind=\"scatter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
